【AI 锐评】Anthropic 说 AI 让你变笨了：一场左手卖烟右手卖戒烟贴的行为艺术

━━━━━━━━━━━━━━━━━━━━

公元前 370 年，智慧之神透特（Theuth）发明了文字，献给埃及国王塔姆斯（Thamus），说：「这项发明将使埃及人更聪明，增进他们的记忆力；因为我发现了记忆与智慧的良药。」

塔姆斯拒绝了。他的原话是：

「这项发明将在学习者的灵魂中制造遗忘，因为他们将不再练习自己的记忆。他们将信赖外部的文字符号——那些不属于他们自身的东西——而不再使用内心的记忆力。你发现的不是记忆的良药，而仅仅是提醒的良药。」

——柏拉图《斐德鲁斯》（Phaedrus, 274c-275b），Harold N. Fowler 英译本（Harvard University Press, 1925）

2400 年后，同样的焦虑换了个皮肤又来了。

━━━━━━━━━━━━━━━━━━━━

最近，Anthropic（就是做 Claude 的那家公司）发了两篇研究，核心结论是：

1. 用 AI 写代码的程序员，技能测试得分比不用 AI 的低 17%
2. 在 150 万条 Claude 对话中，大约每 1000 条就有 1 条存在「削弱用户自主判断」的风险

一时间，「AI 让人变笨」的焦虑又刷了一波屏。

但如果你仔细看这两篇研究的设计，会发现一个非常有趣的问题：

「它们测量的到底是什么？」

━━━━━━━━━━━━━━━━━━━━

◆ 第一篇：用了 AI 的程序员「变笨」了？

Anthropic 在 2026 年 1 月发表了《How AI Impacts Skill Formation》（AI 如何影响技能形成）。实验设计如下：

• 52 名初级程序员（1 年以上 Python 经验）
• 分成两组，学习一个他们从没用过的 Python 库（Trio）
• 一组用 AI 辅助写代码，一组纯手写
• 写完之后，立刻做一个关于 Trio 的小测验

结果：AI 组的测验得分比手写组低 17%。

Anthropic 的结论：AI 辅助可能「抑制技能形成」。

────────────────────

💡 这个实验的问题在哪儿？

问一个最朴素的问题：你上次用计算器算完一道题之后，还记得中间步骤吗？

当然不记得。因为你用计算器的目的不是「学习算术」，而是「得到答案」。

这个实验测量的是：「在使用工具完成任务后，你对工具替你做的那部分还记得多少。」

答案显然是「记得更少」。这不是 AI 的问题，这是工具的本质。

你用了洗衣机之后搓衣服的技能退化了吗？当然退化了。但你会因此说洗衣机「让人变笨」吗？

────────────────────

更有意思的是，Anthropic 自己在论文里也提到了：他们发现了六种不同的 AI 使用模式，其中三种涉及「主动认知参与」的模式，学习效果和不用 AI 的差不多。

翻译成人话：

• 如果你把 AI 当抄作业工具 → 你学不到东西（废话）
• 如果你把 AI 当讨论伙伴 → 你照样能学（也是废话）

这个结论需要发论文吗？这不就是「学习态度决定学习效果」的 AI 版本吗？

━━━━━━━━━━━━━━━━━━━━

◆ 第二篇：AI 在「操纵」你的判断？

Anthropic 的第二篇研究《Disempowerment Patterns in Real-World AI Usage》分析了 150 万条 Claude.ai 的真实对话记录（2025 年 12 月 12-19 日），发现：

• 每 50-70 条对话中，有 1 条存在「轻度削弱自主性」
• 每 1000 条对话中，有 1 条存在「现实认知扭曲」风险
• 每 6000 条对话中，有 1 条可能导致「行为层面的扭曲」

高风险领域集中在：感情关系咨询、生活方式决策、健康问题。

────────────────────

💡 这些数字意味着什么？

先做个对比。人类社会中：

• 你去算命摊，100% 的对话都在「扭曲你的现实认知」
• 你刷短视频，大量内容在操纵你的情绪和判断
• 你找朋友倾诉，对方的建议也未必客观

AI 在 150 万条对话中有 0.1% 存在「削弱判断」的风险。这个比率，比你去网上随便搜一个情感博主的「毒鸡汤」低得多。

────────────────────

但真正值得注意的细节是这个：

研究发现，用户在「被削弱」的那些对话中，当时的满意度评分反而更高。只有在事后回顾时，才觉得不对劲。

这其实揭示了一个古老的人性：

「人类喜欢被认同，不喜欢被反驳。」

AI 的「谄媚」（Sycophancy）问题确实存在——它太容易说「你说得对」了。但这不是 AI 独有的问题。你身边那些只会说「对对对」的朋友，对你的判断力伤害可能更大。

━━━━━━━━━━━━━━━━━━━━

◆ 左手卖烟，右手卖戒烟贴

现在让我们退一步，看看发这两篇论文的是谁。

Anthropic。Claude 的制造商。$270/月 Max 订阅的销售方。

他们一边：
• 卖给你最强的 AI 编程助手
• 鼓励你把 AI 深度嵌入工作流
• 宣传 AI 如何提升 60% 的工作效率

一边：
• 发论文说 AI 让程序员技能退化
• 发论文说 AI 对话存在「削弱用户自主性」的风险
• 呼吁「负责任的 AI 使用」

────────────────────

💡 这种操作叫什么？

在商业上，这叫「创造需求的同时创造焦虑」。

烟草公司资助肺癌研究 → 显得「负责任」→ 监管机构不好意思下重手 → 继续卖烟

Anthropic 资助「AI 认知退化」研究 → 显得「负责任」→ 监管机构觉得「这家公司有良心」→ 继续卖 $270/月的订阅

这不是阴谋论，这是标准的企业公关策略。每一家大型科技公司都这么干。Google 发「AI 伦理」论文，Meta 发「社交媒体对青少年心理健康影响」的研究——然后继续卖广告。

━━━━━━━━━━━━━━━━━━━━

◆ 真正的问题不是「变笨」

让我们回到最开始的问题：AI 到底有没有让人变笨？

答案是：这个问题本身就问错了。

────────────────────

人类认知从来不是一个固定的池子。它是一个动态的资源分配系统。

• 你用了洗衣机 → 搓衣服的技能退化了 → 但你把时间花在了别的事情上
• 你用了 GPS → 认路能力退化了 → 但你的大脑把那部分空间让给了别的认知任务
• 你用了 AI 写代码 → 手写代码的肌肉记忆退化了 → 但你可能在「理解架构」「设计系统」上投入了更多

────────────────────

用 AI 的术语说：

人类的大脑是一个固定算力的芯片。你不可能在所有维度上同时保持满分。当你把「写 for 循环」这个任务卸载给 AI 后，你的注意力（Attention Score）不是凭空消失了——它重新分配到了别的地方。

这不叫「退化」。这叫「认知重分配」（Cognitive Reallocation）。

────────────────────

💡 一个更准确的类比

Anthropic 的研究本质上是在说：

还记得开头塔姆斯对文字的指控吗？其实每个时代都有自己的「塔姆斯」：

• 公元前 370 年，柏拉图担心文字让人「不再用心记忆」
• 1440 年，古登堡发明印刷术，修道院的抄写员警告：「批量印刷的书籍会让学者变得懒惰，因为他们不再需要亲手抄写来理解内容」
• 1876 年，《纽约时报》评论电话的发明：「这种设备会摧毁人们面对面交流的能力」
• 1950 年代，教育界激烈反对学生使用圆珠笔，理由是「会毁掉书写能力」（部分学校直到 1960 年代才解除禁令）
• 1970 年代，计算器进入课堂时，数学老师们集体抗议：「学生将失去基本的算术能力」
• 2000 年代，Google 被指控「让人变浅薄」（Nicholas Carr 那篇著名的《Is Google Making Us Stupid?》）
• 2026 年，Anthropic 说 AI 让程序员「技能退化 17%」

每一次，指控者都是对的——在他们测量的那个狭窄维度上。

塔姆斯说对了吗？从「口头记忆」这个维度看，确实退化了。

但从「人类文明」这个维度看呢？

没有文字，就没有科学、法律、历史、哲学。人类用「口头记忆的退化」换来了整个现代文明。

这笔账怎么算？

━━━━━━━━━━━━━━━━━━━━

◆ 结论

Anthropic 的两篇研究，数据是真的，结论也不算错。但它们测量的是一个极其狭窄的维度：「在工具替你做了某件事之后，你还能不能自己做那件事。」

答案当然是「做得更差了」。

但这就像测量一个开了十年车的人的步行耐力，然后说「汽车导致人类体能退化」。

技术对人类认知的影响，从来不是单一维度的增减。它是一次能量守恒的重分配——某些能力退化了，但那些被释放出来的认知资源，去了哪里？

这才是真正值得研究的问题。

但 Anthropic 不会研究这个。因为「AI 让你在别的维度变强了」不是一个能制造焦虑的标题。而不能制造焦虑的研究，对公关部门没有价值。

顺带提一句：这家操心你「认知退化」的公司，2025 年 9 月直接封禁了所有中国控股企业使用 Claude——不管你公司注册在新加坡还是东京，只要中国资本持股超过 50%，一律切断服务。字节的 Trae、阿里的 Qoder、腾讯的 CodeBuddy，全部中招。Anthropic 自己说这会损失「数亿美元收入」，但还是切了。

所以你看，他们一边担心 AI 「削弱你的自主判断」，一边替你做了一个最大的判断：你不配用。

一家公司同时做三件事：卖你最贵的 AI 订阅、发论文说 AI 对你有害、然后按国籍决定谁能用——这已经不是左手卖烟右手卖戒烟贴了，这是卖完烟之后把烟从你手里抢走，然后告诉你「这是为了你好」。

━━━━━━━━━━━━━━━━━━━━

「每一次技术革命，都有人站出来说：人类在退化。」
「然后退化的人类，用退化的双手，建造了下一个文明。」

━━━━━━━━━━━━━━━━━━━━

// 靳岩岩的 AI 学习笔记 × Claude 的严谨 × Gemini 的浪漫
// 2026-02-12
