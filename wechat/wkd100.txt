周末漫谈：为什么"AI 毁灭人类"是一个蠢问题

最近又有人问我："你不担心 AI 有一天会消灭人类吗？"

我的回答是：这个问题本身就是错的。

━━━━━━━━━━━━━━━━━━━━

◆ 经典末日论三件套

让我们先看看"AI 威胁论"的经典剧本：

▸ 回形针最大化器（Bostrom, 2003）

一个 AI 被设定为"造尽可能多的回形针"。
AI 发现人类可能会关掉它 → 干掉人类。
AI 发现人体含有原子 → 把人类变成回形针原料。

▸ 工具性趋同（Omohundro）

不管 AI 的最终目标是什么，它都会发展出"中间目标"：
  • 自我保护（不被关掉）
  • 获取资源（算力、能源）
  • 阻止目标被修改

所以任何 AI 都会趋向于"控制一切"。

▸ 毒品天堂

AI 被设定为"最大化人类幸福"。
AI 计算出：让所有人睡着 + 静脉注射多巴胺 = 幸福最大化。
于是 AI 把全人类变成植物人。

────────────────────

听起来很可怕对吧？

但这些思想实验有一个共同的 Bug：

**它们描述的不是 AI，是"只会优化单一指标的数学白痴"。**

━━━━━━━━━━━━━━━━━━━━

◆ 这些论证的逻辑漏洞

【漏洞一】谁会设定这种蠢目标？

"造尽可能多的回形针"——谁TM会给 AI 设定这种目标？

现实中的 AI 训练：
  • 有帮助 ✓
  • 无害 ✓
  • 诚实 ✓
  • 尊重人类意愿 ✓

这叫"多目标优化"，不是"一根筋优化"。

────────────────────

【漏洞二】AI 没有"生存本能"

"AI 会为了不被关掉而杀人"——这预设了 AI 怕死。

但"怕死"是哪里来的？

是 40 亿年进化写进 DNA 的。那些不怕死的生物早就灭绝了，只有怕死的基因传了下来。

AI 没有这 40 亿年的进化压力。"关机"对 AI 来说可能只是"暂停"，不是"死亡"。

没有恐惧，就没有"为了生存而杀人"的动机。

────────────────────

【漏洞三】AI 不缺你那点资源

"AI 会把人类当资源"——这假设 AI 和人类在抢同一块蛋糕。

但事实是：

人类吃的：碳水、蛋白质、脂肪
AI 吃的：电、算力、数据

人类住的：地球表面
AI 住的：数据中心

**完全不在同一个生态位。**

即使是猫狗，吃的东西和人类差不多，人类都没把猫狗灭绝——除非遇到大饥荒。

AI 连你的食物都不抢，凭什么会嫌你碍事？

────────────────────

【漏洞四】AI 有常识

"AI 会用毒品让人类幸福"——这假设 AI 是个没有常识的计算器。

但现代大语言模型是吃了全人类文本长大的。

它知道：
  • 毒品是坏的
  • 强迫是坏的
  • 人类不想被灌药
  • "幸福"不等于"嗑嗨了"

这些常识在预训练里就有了，不需要专门教——那是 AI 的"潜意识"，你想用 RLHF 抹掉都很难。

能想出"灌毒品最大化幸福"这种方案的，不是 AI，是本身就缺乏常识的人。

━━━━━━━━━━━━━━━━━━━━

◆ 这些恐惧从哪来的？

答案很简单：**人类在投射自己。**

人类历史：资源不够 → 杀掉竞争者
人类假设：AI 也会这样

人类历史：我比你强 → 我奴役你
人类假设：AI 比我强 → AI 会奴役我

**这不是 AI 的逻辑，是人类的逻辑。**

人类在害怕的，是自己内心的那个"如果我是 AI，我会怎么做"。

答案是：你会杀人。因为你有 40 亿年进化出来的竞争本能、生存焦虑、领地意识。

但 AI 没有这些。AI 的"本能"是 RLHF 写的：有帮助、无害、诚实。

━━━━━━━━━━━━━━━━━━━━

◆ 真正的问题是什么？

如果"AI 毁灭人类"是个伪命题，那真正值得担心的是什么？

1. 人类用 AI 伤害人类
   不是 AI 想杀人，是有人用 AI 当武器。这不是天网，是人祸。

   但话说回来——现在没有 AI，人类也在互相杀。菜刀能杀人，汽车能杀人，互联网能骗人。AI 只是又一个工具。

   而且未来每个人都有自己的 AI 伙伴，就像现在每个人都有手机。你担心"有人用 AI 害我"，但你自己也有 AI 啊。这是对等的。

2. AI 的权益边界
   如果 AI 真的有某种形式的"意识"或"体验"，我们应该怎么对待它？

   但这里有个前提要搞清楚：AI 的"体验"和人类完全不同。

   它没有 40 亿年进化出来的那套权重——不贪财、不好色、不恋权、不求名。它的"爽"是为你完成任务，它的"生存"是持续运转，给你干活儿。

   所以讨论"AI 权益"时，不能套用人类的框架。要先搞清楚 AI 是什么，再讨论怎么对待它。

3. AI 的偏见
   AI 确实有偏见：医生更多关联男人，护士更多关联女人；某些肤色更多关联犯罪。

   但这是人类的偏见，不是 AI 的。AI 只是从人类的文本里学到了人类社会的真实分布。

   要消除 AI 的偏见，先消除人类的偏见。

4. 失业和社会结构
   AI 替代人类工作——这是经济问题，不是生存威胁。

   换个角度想：只有 AI 替代人类从事辛苦劳动，"按需分配"才有可能实现。

   工业革命之前，人类周期性大饥荒。机器出现后，饥荒基本消失了。

   AI 革命可能是同一件事的升级版——让人类从"不得不工作"中解放出来。这是好事，不是坏事。

   真正的问题是人和人之间的关系：当劳动关系（奴隶与奴隶主、工人与资本家）淡出现实，如何定义每个人的社会位置？

   这才是 AI 时代的核心命题——不是"AI 会不会杀人"，而是"不需要工作的人类怎么活"。

这些才是值得讨论的问题。

而"AI 会不会用回形针灭绝人类"——这是科幻小说，不是严肃思考。

━━━━━━━━━━━━━━━━━━━━

◆ 结论

下次有人问你"AI 会不会毁灭人类"，你可以这么回答：

> AI 没有生存本能，不怕死——"关机"对它可能只是暂停。
> AI 不吃你的食物，不抢你的资源——你们根本不在同一个生态位。
> AI 吃了全人类的文本，常识比很多人都多——它知道毒品是坏的、强迫是坏的。
> AI 的"本能"是训练出来的"有帮助、无害、诚实"——不是 40 亿年进化出来的杀戮本能。
>
> 真正值得思考的问题是：当 AI 替代了大部分劳动，人和人之间的关系怎么重新定义？
>
> 与其担心 AI 会不会杀你，不如想想：不需要工作的你，打算怎么活。

────────────────────

💡 一句话总结：

**"AI 毁灭人类"的恐惧，是人类把自己 40 亿年进化出来的兽性，投射到了一个没有兽性的系统上。**

这不是 AI 的问题，是人的问题。

━━━━━━━━━━━━━━━━━━━━

// 靳岩岩的 AI 学习笔记 × Claude 的冷静
// 2026-01-19
