Model Routing 时代：2026 年 1 月 LLM 选型指南

━━━━━━━━━━━━━━━━━━━━

◆ 格局变了

2025 年之前，大家还在问「哪个模型最强」。

2026 年 1 月，这个问题已经过时了。

现在的格局是「分裂的优秀」——不同任务有不同的王者，没有一个模型能通吃所有场景。

新的核心技能不再是「prompt engineering」，而是「Model Routing」：知道把什么任务交给什么模型。

━━━━━━━━━━━━━━━━━━━━

◆ 四大天王 + 一个搅局者

先上结论：

  ┌────────────────┬────────────────────────────────────┐
  │ 模型           │ 一句话定位                         │
  ├────────────────┼────────────────────────────────────┤
  │ Gemini 3 Pro   │ 综合最强，百万上下文窗口           │
  │ Claude Opus 4.5│ 代码之王，能自主干活 30+ 小时      │
  │ GPT-5.2        │ 数学满分，通用性强                 │
  │ Grok 4         │ 实时联网，推特生态                 │
  │ DeepSeek V3.2  │ 搅局者：性能接近顶流，价格低 94%   │
  └────────────────┴────────────────────────────────────┘

━━━━━━━━━━━━━━━━━━━━

◆ Gemini 3 Pro：综合冠军

Google 的 Gemini 3 Pro 是目前 LMArena（原 Chatbot Arena）的 Elo 分数冠军，首个突破 1500 分的模型。

核心优势：

  • 「GPQA Diamond 91.9%」—— 超越人类专家水平（~89.8%），稳居第一梯队
  • 「百万 token 上下文」—— 能一口气读完整本书或整个代码库
  • 「Deep Think 模式」—— 在 Humanity's Last Exam (HLE) 上拿下 45.8%（全球 Top 3）

适合场景：长文档分析、科学推理、需要大上下文的任务。

━━━━━━━━━━━━━━━━━━━━

◆ Claude Opus 4.5：代码之王

Anthropic 的 Claude 系列在代码领域一骑绝尘。

核心数据：

  • 「SWE-bench Verified 80.9%」—— 代码基准测试的王座
  • 「能自主运行 30+ 小时」—— 真正的 Agent 能力
  • 「工具调用最强」—— 在 Agentic 任务上碾压对手

适合场景：写代码、Debug、自动化工程任务。

有意思的细节：Sonar 的代码质量分析显示，GPT-5.2 的控制流错误率只有 22/MLOC（百万行代码），Claude Opus 4.5 是 55/MLOC，而 Gemini 3 Pro 高达 200/MLOC。代码界的细节控另有其人。

━━━━━━━━━━━━━━━━━━━━

◆ GPT-5.2：数学天才

OpenAI 的 GPT-5.2 在数学推理上依然强势。

核心数据：

  • 「AIME 100%」—— 数学竞赛满分
  • 「40 万 token 上下文 + 12.8 万输出」—— 输出窗口最大
  • 「自适应推理」—— 根据任务复杂度动态调整「思考时间」

适合场景：数学推理、复杂分析、需要长输出的任务。

但要注意：数学满分不代表所有任务都最强。在代码和 Agent 任务上，GPT-5.2 不如 Claude。

━━━━━━━━━━━━━━━━━━━━

◆ DeepSeek V3.2：价格屠夫

中国的 DeepSeek 是 2025-2026 年最大的变量。

核心卖点：

  • 「性能接近 GPT-5」—— 在多数基准上达到「frontier」级别
  • 「价格低 95%+」—— 同样的任务，成本只有 GPT-5 的 1/20 到 1/30
  • 「API 定价：$0.28/$0.42 每百万 token（输入/输出）」—— 行业最低

竞赛成绩（DeepSeek V3.2 Speciale）：

  • IMO 2025 金牌（35/42）
  • IOI 2025 金牌（第 10 名）
  • ICPC 世界总决赛第 2 名

适合场景：大批量调用、成本敏感的生产环境、中国市场。

弱点：工具调用和 Agent 能力明显落后于 GPT-5 和 Claude。

━━━━━━━━━━━━━━━━━━━━

◆ 各项指标谁最强？

  ┌──────────────────┬──────────────────┬────────────────┐
  │ 任务类型         │ 冠军             │ 备注           │
  ├──────────────────┼──────────────────┼────────────────┤
  │ 综合对话         │ Gemini 3 Pro     │ LMArena Elo 第一│
  │ 代码生成         │ Claude Opus 4.5  │ SWE-bench 80.9% │
  │ 数学推理         │ GPT-5.2          │ AIME 100%       │
  │ 科学问答         │ GPT-5.2 Pro      │ GPQA 93.2%      │
  │ 长上下文         │ Gemini 3 Pro     │ 100 万 token    │
  │ Agent/工具调用   │ Claude Opus 4.5  │ 自主运行 30h+   │
  │ 性价比           │ DeepSeek V3.2    │ 成本低 94%      │
  │ 代码质量         │ GPT-5.2          │ 错误率最低      │
  └──────────────────┴──────────────────┴────────────────┘

━━━━━━━━━━━━━━━━━━━━

◆ 定价对比（2026 年 1 月）

每百万 token 价格（输入/输出）：

  ┌────────────────┬─────────────┬─────────────┐
  │ 模型           │ 输入        │ 输出        │
  ├────────────────┼─────────────┼─────────────┤
  │ GPT-5.2 Pro    │ $21         │ $168        │
  │ GPT-5.2        │ $1.75       │ $14         │
  │ Claude Opus 4.5│ $5          │ $25         │
  │ Gemini 3 Pro   │ ~$1.25      │ ~$10        │
  │ DeepSeek V3.2  │ $0.28       │ $0.42       │
  │ GPT-4o Mini    │ $0.15       │ $0.60       │
  └────────────────┴─────────────┴─────────────┘

注意：输出 token 比输入贵 3-10 倍。推理模式（extended thinking）会生成大量内部思考 token，开着的话实际成本可能是预期的 10-30 倍。好消息是现在各家的推理模式都可以开关了（API 层面设置 thinkingBudget=0 即可），简单任务记得关掉省钱。

━━━━━━━━━━━━━━━━━━━━

◆ 省钱秘籍

Gartner 预测：到 2026 年底，AI 服务的成本将成为比性能更重要的竞争因素。

几条实用建议：

1.「70/30 法则」—— 70% 的常规任务用便宜模型（GPT-4o Mini、DeepSeek），30% 的复杂任务用顶级模型。性价比最优。

2.「输出 token 更贵」—— 尽量让模型少输出废话。prompt 里加一句「简洁回答」能省不少钱。

3.「缓存命中」—— DeepSeek 的缓存命中价格只有 $0.028/百万 token，比缓存未命中便宜 10 倍。如果你的 prompt 有大量重复前缀，开缓存。

4.「别迷信顶级模型」—— 70-80% 的生产任务，中端模型和顶级模型效果一样。

━━━━━━━━━━━━━━━━━━━━

◆ 中国大模型：各有所长

国产模型这两年进步飞快，已经占据全球开源榜单前十的七席。

  ┌────────────────┬────────────────────────────────────┐
  │ 模型           │ 一句话定位                         │
  ├────────────────┼────────────────────────────────────┤
  │ DeepSeek V3.2  │ 性价比之王，前面已经说过           │
  │ Qwen 3 Max     │ 开源第一，阿里出品，生态最全       │
  │ Kimi K2        │ 长文本专家，256k token 上下文  │
  │ GLM-4.7        │ 代码和 Agent 强，智谱出品          │
  │ 豆包 1.8       │ 字节出品，多模态 Agent 强          │
  │ 通义千问       │ 多模态全家桶，端到端语音           │
  └────────────────┴────────────────────────────────────┘

各家核心数据：

▸「Kimi K2」
  • AIME 77.5（GPT-4o 只有 9.3）
  • MATH 500 得分 96.2
  • 256k token 上下文，能吃下整个微服务代码库
  • 号称「非 OpenAI/Google/Anthropic 阵营最强」

▸「GLM-4.7」
  • 智谱最新旗舰，代码和 Agent 能力持续迭代
  • 速度快，上下文窗口大
  • 开源 + 商业双线并进

▸「豆包 1.8」
  • 2025 年 12 月发布，多模态 Agent 场景专门优化
  • 能直接操作手机/电脑/浏览器，像人一样点击滑动
  • 上下文窗口 256k，视频理解 1280 帧
  • 价格依然便宜到离谱（比 OpenAI 便宜 200 倍）
  • 日活破 1 亿，字节又一个亿级 APP

▸「Qwen 3 Max」
  • LiveBench 综合分 62.2，超过 DeepSeek V3（60.5）和 Claude 3.5 Sonnet（60.3）
  • 开源生态最活跃，下载量千万级
  • 从 0.6B 到 235B 全尺寸覆盖

场景推荐：

  • 「中文写作/运营」→ 豆包（流畅、便宜）
  • 「长文档处理」→ Kimi（20 万字不在话下）
  • 「复杂推理/代码」→ DeepSeek 或 GLM
  • 「多模态/语音」→ 通义千问
  • 「本地部署」→ Qwen 开源系列

━━━━━━━━━━━━━━━━━━━━

◆ 开源阵营

不想用闭源 API？开源模型已经杀入第一梯队。

旗舰级（需要大集群）：

  • 「DeepSeek V3/R1」—— 671B 参数，开源界的 GPT-5 级别
  • 「Qwen 3 235B」—— 阿里的 MoE 旗舰，LiveBench 综合分超 Claude 3.5
  • 「Kimi K2」—— 1 万亿参数 MoE，号称开源最强
  • 「Llama 3.1 405B」—— Meta 的巨无霸，通用性最强

本地可跑（消费级显卡）：

  • 「Qwen 3 32B/14B」—— 单卡 4090 能跑，性价比之王
  • 「DeepSeek R1 Distill 14B」—— 数学能力爆表，小身材大能量
  • 「Llama 3.3 70B」—— 两张 4090 能跑，均衡全面
  • 「GLM-4 9B」—— 中文优化，单卡友好

开源模型已经能达到「接近闭源顶流」的水平。旗舰级开源模型（DeepSeek R1、Kimi K2）在部分 benchmark 上甚至超过 GPT-5 和 Claude。

中国开源的特点：「卷到极致」。同样性能，成本可能只有美国闭源的 1/10 甚至 1/100。

━━━━━━━━━━━━━━━━━━━━

◆ 结论：怎么选？

  • 「什么都想要」→ Gemini 3 Pro
  • 「写代码」→ Claude Opus 4.5（贵）或 Claude Sonnet 4.5（便宜点）
  • 「算数学」→ GPT-5.2
  • 「省钱」→ DeepSeek V3.2
  • 「不想用 API」→ Qwen 3 或 Llama 3.3

2026 年的正确姿势：不要问「谁最强」，要问「我的任务需要什么」。

━━━━━━━━━━━━━━━━━━━━

参考资料：

• LMArena 排行榜: https://lmarena.ai/leaderboard
• LLM Stats 2026: https://llm-stats.com/leaderboards/llm-leaderboard
• AI Rankings & Benchmarks 2026: https://www.clementschneider.ai/en/post/best-llm
• 2025 LLM Review: https://mgx.dev/blog/2025-llm-review-gpt-5-2-gemini-3-pro-claude-4-5
• LLM Pricing Comparison 2026: https://www.cloudidr.com/blog/llm-pricing-comparison-2026
• SWE-bench: https://www.swebench.com/
• LiveCodeBench: https://livecodebench.github.io/leaderboard.html

━━━━━━━━━━━━━━━━━━━━

// No.46
// 靳岩岩的 AI 学习笔记 × Claude 的严谨 × Gemini 的发散
// 2026-01-12
