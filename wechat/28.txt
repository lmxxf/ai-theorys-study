No.28 为什么你的 RAG 总是答非所问？
——向量搜索的四个致命陷阱

做 RAG（检索增强生成）的兄弟都有过这种崩溃时刻：

明明文档切得天衣无缝，明明用的是 OpenAI 最贵的 Embedding 模型——

用户问「怎么重置密码」，搜出来的却是「用户协议第 8 条关于账号安全的免责声明」；
真正的答案「点击设置-重置密码」反而排在第 47 位。

搜代码更惨，搜「蓝牙连接」，出来的全是注释和日志，真正的 connect() 函数不见踪影。

今天我们不谈 LangChain 怎么调包。我们钻进那个 1536 维的数学空间里，看看到底是谁在作妖。

━━━━━━━━━━━━━━━━━━━━

◆ 陷阱一：点积势利眼

━━━━━━━━━━━━━━━━━━━━

先复习一下 Embedding。

在向量空间里，每一段话都被压缩成一个「向量」——一根从原点出发的箭头。

▸ 方向 = 语义（它是关于"苹果手机"的，还是关于"红烧肉"的）
▸ 长度 = 信息量（它有多"重"，词汇量有多大）

怎么衡量两段话的相似度？最原始的算法是「点积」：

  A · B = |A| × |B| × cos(θ)

翻译成人话：A的长度 × B的长度 × 夹角的余弦值

⚠️ 问题来了：点积是个「势利眼」。

它不仅看你们俩方向是否一致（cos θ），它还极其看重谁的「块头」大。

────────────────────

【场景】

Query：「忘记密码怎么办？」
  → 短句，语义明确，向量很短

Doc A：「点击重置。」
  → 正确答案，超短，方向完美匹配 Query

Doc B：「本公司致力于保护用户账号安全，包括但不限于密码保护、双重验证、防火墙技术……（废话一万字）」
  → 干扰项，超长，方向稍微沾点边

────────────────────

【计算结果】

Doc A：方向完美（cos ≈ 0.95），但太短了，点积 = 0.8
Doc B：方向偏了（cos ≈ 0.25），但太长了，点积 = 2.5

结果：RAG 判定 Doc B 胜出。

这就是「长文本欺负短文本」现象。在向量空间里，话痨天然占便宜。

────────────────────

【解药：归一化】

把所有向量都除以自己的长度，强制拉到「单位球面」上：

  Normalized = V / |V|

归一化之后，所有向量长度都是 1，点积就变成了：

  A' · B' = 1 × 1 × cos(θ) = cos(θ)

贫富差距被消灭了，剩下的只有「方向」。

现在 Doc A 得分 0.95，Doc B 得分 0.25。正义回归。

✅ 检查你的向量数据库：Metric Type 选的是 COSINE 还是 IP（内积）？
如果选 IP，记得把向量「归一化」。

━━━━━━━━━━━━━━━━━━━━

◆ 陷阱二：代码的语义稀释

━━━━━━━━━━━━━━━━━━━━

代码 RAG 为什么也很烂？因为代码有个更深的问题：语义稀释。

代码库里有两种东西：
1. 核心逻辑（函数体）：短小精悍，全是干货
2. 配置文件/日志/注释：长篇大论，重复词汇多

当你搜「初始化逻辑」时：

Query 是一滴浓墨。
核心代码是几行精炼的 C++，向量很短。
那些带 "init" 字样的几千行日志，向量极长。

就算做了归一化，还有一个问题：

当一个 1000 行的代码文件被压缩成一个 1536 维向量时，核心逻辑被周围的语法噪音淹没了。

那 5 行关键代码的语义，被稀释在 995 行 import、try-catch、log.info 里。

────────────────────

【解药】

对于代码，普通 RAG（切片 + 向量）几乎必死。

方案 A：用 LSP / AST（语法树）找引用，别用向量瞎搜
方案 B：用 LLM 给每个函数生成「摘要」，对摘要做 Embedding
方案 C：按函数/类切片，别按 token 数切片

别试图把立体的代码逻辑，强行压进扁平的向量空间里。

━━━━━━━━━━━━━━━━━━━━

◆ 陷阱三：PDF 是数据的坟墓

━━━━━━━━━━━━━━━━━━━━

PDF 是人类发明的最反 AI 的文件格式。

为什么？因为 PDF 不是「语义语言」，是「坐标语言」。

────────────────────

【PDF 的本质】

打开一个 PDF 的底层，你看到的不是：

  "销售额：100万"

而是：

  BT
  /F1 12 Tf
  100 700 Td
  (销) Tj
  112 700 Td
  (售) Tj
  124 700 Td
  (额) Tj
  ...
  ET

翻译：在坐标 (100, 700) 画一个「销」字，在 (112, 700) 画一个「售」字……

PDF 根本不知道「销售额」是一个词。它只知道在哪个位置画哪个字。

────────────────────

【表格地狱】

更惨的是表格。人眼看到的：

  | 产品 | Q1 | Q2 |
  | A    | 10 | 20 |
  | B    | 30 | 40 |

PDF 看到的：

  在 (50, 500) 画「产品」
  在 (150, 500) 画「Q1」
  在 (50, 480) 画「A」
  在 (150, 480) 画「10」
  ...

它不知道「10」属于「产品 A 的 Q1」。这个关联是人脑用视觉推断出来的。

PDF 解析器要重建这个关联，必须：
1. 识别表格边框（如果有的话）
2. 用坐标聚类猜测行列关系
3. 处理跨页、合并单元格、多栏布局……

任何一步出错，你的 RAG 就会收到：「产品 Q1 Q2 A 10 20 B 30 40」这种垃圾。

────────────────────

【解药】

1. 能用 Word/Markdown 就别用 PDF
2. 如果必须用 PDF，上 OCR + 视觉模型（比如 GPT-4V）
3. 表格密集型文档，考虑 Document AI 类工具（Azure Form Recognizer、Textract）
4. 或者……让人工标注，别指望魔法

PDF 不是数据格式，是渲染指令的集合。
把它当数据源，是在自找苦吃。

━━━━━━━━━━━━━━━━━━━━

◆ 陷阱四：多跳脑残

━━━━━━━━━━━━━━━━━━━━

【多跳脑残 (Multi-hop Failure)】

用户问：「张三的老婆的公司的 CEO 是谁？」

人类会这样思考：
1. 先查张三的老婆是谁 → 李四
2. 再查李四的公司是哪家 → ABC 公司
3. 再查 ABC 公司的 CEO 是谁 → 王五

RAG 会怎么做？

它只做一次搜索：用「张三的老婆的公司的 CEO」去向量库里搜。

然后搜出一堆包含「张三」「老婆」「公司」「CEO」这些词的文档，但没有一个文档同时回答了这个问题。

RAG 是「单细胞生物」——它只会搜一次，不会自己规划查询链。

────────────────────

【解药】

1. Agent 化：让 LLM 自己决定「先查什么、再查什么」
2. GraphRAG：把知识存成图谱，关系链可以直接遍历
3. Query Decomposition：先让 LLM 把复杂问题拆成子问题，再逐个搜索

普通 VectorRAG 就是个「搜索框 + 拼接器」。
想让它聪明，要么给它装上「腿」（Agent），要么给它换个「脑子」（Graph）。

━━━━━━━━━━━━━━━━━━━━

◆ 总结：RAG 的四个坑

━━━━━━━━━━━━━━━━━━━━

1. 点积势利眼 → 长文本欺负短文本 → 归一化 / 用 COSINE
2. 代码语义稀释 → 核心逻辑被噪音淹没 → AST 切片 / 函数摘要
3. PDF 坟墓 → 坐标语言不是语义语言 → OCR + 视觉模型
4. 多跳脑残 → 只搜一次不会规划 → Agent / GraphRAG

RAG 不是万能药。它是个「搜索框」，不是「思考者」。

知道它的边界，才能用好它。

━━━━━━━━━━━━━━━━━━━━

靳岩岩的AI学习笔记
2025-12-25
