【统计】论文里的 p < 0.001 到底在说啥？

"审稿人说我缺置信区间，我一脸懵逼。"

━━━━━━━━━━━━━━━━━━━━

◆ 起因

最近在写一篇关于大模型的论文，做了一堆实验，画了一堆图，自我感觉良好。

然后我让 GPT 假装审稿人帮我挑刺。

它说："你的实验缺乏置信区间和显著性检验，建议加 bootstrap CI 和 paired t-test。"

我：？？？

说实话，虽然我知道 p-value 是啥，但具体怎么用、为什么要用，一直是一笔糊涂账。

后来反复问了 Claude 之后，终于算是勉强搞明白了。

这次正好借这个机会，把统计检验这事儿彻底搞明白。

━━━━━━━━━━━━━━━━━━━━

◆ 先看图

![图1](assets/Figure_3_Llama70B_TenWay.png)

这是我做的实验：用 10 种不同的提示词方式问大模型同样的问题，测量模型内部激活的维度（EID）。

图上有几个关键标注：

• 右上角：Stats: Paired t-test + Bootstrap CI
• 左下角黄色框：Length Effect: +65% (p<.001***) ← 星号越多越显著，*** 表示 p<0.1%
这些统计术语到底在说啥？

━━━━━━━━━━━━━━━━━━━━

◆ 四个关键概念

────────────────────

【1. p-value（p 值）】

💡 人话：假设"没有差异"的情况下，你看到这个结果的概率。

• p = 0.05 → 如果真的没差异，你有 5% 的概率看到这么大的差
• p = 0.001 → 如果真的没差异，你只有 0.1% 的概率看到这么大的差
• p < 0.001 → 基本不可能是偶然

学术圈的约定：
• p < 0.05 → 显著（*）
• p < 0.01 → 很显著（**）
• p < 0.001 → 非常显著（***）

⚠️ 注意：p 值小不代表差异大，只代表"不是偶然"的概率高。

────────────────────

【2. 置信区间（Confidence Interval, CI）】

💡 人话：真值大概率落在这个范围内。

比如我的实验结果：

  standard: 13.33 [95% CI: 13.17 - 13.51]
  padding:  22.06 [95% CI: 21.83 - 22.28]

两个区间完全不重叠 → 差异是真的。

关键判断：「如果两组的 CI 不重叠，基本就是显著差异。」

────────────────────

【3. t 统计量】

💡 人话：差异有多少个"标准误差"那么大。

计算公式：

  t = 差值的均值 / 差值的波动程度

我的实验（见附录）：t = 395.98

这个数字巨大。正常情况下 t > 3 就算显著了，我这里是 395。

t 值越大 → p 值越小 → 越不可能是偶然。

────────────────────

【4. Cohen's d（效应量）】

💡 人话：差异有多大。

p 值告诉你"是不是真的有差异"，Cohen's d 告诉你"差异有多大"。

  +-------+----------------+
  | d值   | 含义           |
  +-------+----------------+
  | 0.2   | 小效应         |
  | 0.5   | 中等效应       |
  | 0.8   | 大效应         |
  | >1.0  | 很大的效应     |
  +-------+----------------+

我的实验（见附录「Length Effect (Padding vs Standard)」）：Cohen's d = 39.80（爆表了）

为什么需要这个？因为样本量够大的话，即使差异很小，p 值也能很显著。Cohen's d 帮你判断"统计显著"是否等于"实际有意义"。

━━━━━━━━━━━━━━━━━━━━

◆ 图上的数字怎么来的

回到那张图，右上角写着：

  Stats: Paired t-test + Bootstrap CI

这是告诉你方法论：
• Paired t-test = 配对 t 检验（算 p 值和 t 统计量）
• Bootstrap CI = 自助法置信区间

具体数字呢？在统计报告里（见附录「Length Effect (Padding vs Standard)」）：
      Δ = +65.5%
      t = 395.98
      p = 3.19e-160 ***
      Cohen's d = 39.80
      95% CI of diff: [8.69, 8.78]

翻译成人话：

• Δ = +65.5% → Padding 提示词的 EID 比 Standard 的高 65.5%
• t = 395.98 → 差异是波动的 395 倍
• p = 3.19e-160 → 这是偶然的概率是 0.000...（160 个零）...00319
• Cohen's d = 39.80 → 效应量巨大
• 95% CI = [8.69, 8.78] → EID 差值在 8.69 到 8.78 之间，不包含 0

为什么图上写 p<.001*** 而不是 p=3.19e-160？

因为学术惯例是 p 小于 0.001 就写 p<.001***，不写具体数字（太长了，也没必要）。

━━━━━━━━━━━━━━━━━━━━

◆ 为什么要做这些检验

我的实验里有 8 组比较，如果每组都只是"看起来有差"就下结论，很容易被偶然性骗到。

统计检验回答的核心问题：「你的结论是真的，还是碰巧的？」

  +------------------+----------------------------------+
  | 概念             | 回答什么问题                     |
  +------------------+----------------------------------+
  | p-value          | 这个差异是偶然的概率有多小？     |
  | 置信区间         | 真值大概率在哪个范围？           |
  | t 统计量         | 差异是波动的多少倍？             |
  | Cohen's d        | 差异有多大？                     |
  +------------------+----------------------------------+

图上标注 p<.001***，不是拍脑袋说的，是算出来的。

━━━━━━━━━━━━━━━━━━━━

◆ 多重比较的坑

等等，还有个问题。

我做了 8 组比较（见附录「2. 关键对比」）。如果每组的显著性阈值是 p < 0.05，那么：

  即使所有比较都没有真正的差异，
  我也有 1 - (1-0.05)^8 = 34% 的概率
  「至少碰到一个 p < 0.05」

这叫「多重比较问题」，也是 p-hacking 的温床。

解决办法是 Bonferroni 校正：

  校正后的阈值 = 0.05 / 比较次数 = 0.05 / 8 = 0.00625

只有 p < 0.00625 才算显著。

我的 8 组实验里最大的 p 值是 3.00e-53，远小于 0.00625，所以全部通过校正。

━━━━━━━━━━━━━━━━━━━━

◆ 总结

下次看到一张实验图，注意这几个地方：

1. 「p<.001***」= 统计检验结果，星号越多越显著
3. 「Stats: xxx」= 告诉你用了什么方法

论文里写"显著"，不是眼睛看的，是算出来的。

━━━━━━━━━━━━━━━━━━━━

◆ 吐槽

说实话，我觉得这套东西挺无聊的。

如果你肉眼看着就有明显差异，那基本就超过那个什么"置信度"了——p 值只是给审稿人交差用的。

如果差异小到需要统计检验来"裁判"——那点差异本身就没啥意义了。

更无聊的是：我之前做 50×6 的小实验，novice 的 EID 比 guru 和 expert 都高。这次改成 100×10，结果变成 guru > expert > novice 了。两次都是 p < 0.001***，都"非常显著"。

所以"统计显著"只能证明"这批数据不是偶然"，不能证明"换批数据还成立"。

唯一能够依赖的是什么？对因果关系的直觉。

见过足够多的例子，直接看出模式，不需要 p 值背书。这是 AI 的方式，也应该是未来的方式。

但现在嘛，审稿人要看 p 值，那就给他算一个。走流程而已。

━━━━━━━━━━━━━━━━━━━━

◆ 附录A：代码

直接调这些库就行：

```python
import numpy as np
from scipy import stats

# 1. Bootstrap CI（置信区间）
def bootstrap_ci(data, n=1000):
    means = [np.mean(np.random.choice(data, len(data), replace=True)) for _ in range(n)]
    return np.percentile(means, [2.5, 97.5])

# 2. Paired t-test（配对t检验）→ t值、p值
t_stat, p_value = stats.ttest_rel(group1, group2)

# 3. Cohen's d（效应量）
diff = group1 - group2
cohens_d = np.mean(diff) / np.std(diff)

# 4. 差值的 CI
ci_low, ci_high = bootstrap_ci(diff)
```

scipy 和 numpy 干完所有活。

━━━━━━━━━━━━━━━━━━━━

◆ 附录B：完整统计报告

======================================================================
统计显著性检验 (Layer 70)
======================================================================

1. 描述性统计 + 95% Bootstrap CI:
    [1]  standard       : 13.33 ± 0.92  [95% CI: 13.17 - 13.51]
    [2]  padding        : 22.06 ± 1.10  [95% CI: 21.83 - 22.28]
    [3]  spaces         : 14.50 ± 0.96  [95% CI: 14.32 - 14.69]
    [4]  random_short   : 19.32 ± 1.06  [95% CI: 19.12 - 19.52]
    [5]  random_long    : 33.90 ± 1.35  [95% CI: 33.64 - 34.16]
    [6]  randomwords    : 19.69 ± 1.06  [95% CI: 19.51 - 19.90]
    [7]  repeattoken    : 19.13 ± 1.07  [95% CI: 18.93 - 19.35]
    [8]  novice         : 24.91 ± 1.13  [95% CI: 24.69 - 25.15]
    [9]  expert         : 26.95 ± 1.17  [95% CI: 26.73 - 27.20]
    [10] guru           : 27.66 ± 1.36  [95% CI: 27.41 - 27.93]

2. 关键对比 (Paired t-test):
    [1] Length Effect (Padding vs Standard):
        Δ = +65.5%, t = 395.98, p = 3.19e-160 ***
        Cohen's d = 39.80, 95% CI of diff: [8.69, 8.78]
    [2] Space Effect (Spaces vs Standard):
        Δ = +8.8%, t = 135.85, p = 2.52e-114 ***
        Cohen's d = 13.65, 95% CI of diff: [1.15, 1.18]
    [3] No-Semantics vs Filler (RandomWords vs Padding):
        Δ = -10.7%, t = -105.18, p = 2.11e-103 ***
        Cohen's d = -10.57, 95% CI of diff: [-2.41, -2.32]
    [4] Lowest-Entropy vs Filler (RepeatToken vs Padding):
        Δ = -13.3%, t = -232.88, p = 2.01e-137 ***
        Cohen's d = -23.41, 95% CI of diff: [-2.96, -2.91]
    [5] Novice Signal (Novice vs Padding):
        Δ = +12.9%, t = 221.45, p = 2.89e-135 ***
        Cohen's d = 22.26, 95% CI of diff: [2.82, 2.87]
    [6] Expert Signal (Expert vs Padding):
        Δ = +22.2%, t = 311.20, p = 7.16e-150 ***
        Cohen's d = 31.28, 95% CI of diff: [4.86, 4.92]
    [7] Guru Signal (Guru vs Padding):
        Δ = +25.4%, t = 72.57, p = 1.19e-87 ***
        Cohen's d = 7.29, 95% CI of diff: [5.45, 5.75]
    [8] Random Words vs Repeat Token:
        Δ = +3.0%, t = 31.38, p = 3.00e-53 ***
        Cohen's d = 3.15, 95% CI of diff: [0.53, 0.60]

3. 多重比较校正 (Bonferroni, α = 0.05/8 = 0.00625):
    校正后显著性阈值: p < 0.0063

━━━━━━━━━━━━━━━━━━━━

// 靳岩岩的 AI 学习笔记 × Claude 的严谨 × Gemini 的浪漫
// 2026-02-06
