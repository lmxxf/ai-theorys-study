【Grokking实验验证】维度骤降、陪集结构、两阶段模型

前天的公众号（ https://mp.weixin.qq.com/s/k275DseWLO4iIX79iDFdbg ）提出了一个假说：

「Grokking = 从锯齿曲线到平滑流形的拓扑相变」

理论再漂亮，不做实验就是空谈。这两天我们动手验证了这个假说。

结果：假说得到支持，但需要修正——不是一次相变，是「两阶段」。

━━━━━━━━━━━━━━━━━━━━

◆ 实验设计

━━━━━━━━━━━━━━━━━━━━

我们设计了两组实验：

• 实验组1：模加法 (a + b) mod 97
• 实验组2：模乘法 (a × b) mod 97

为什么选这两个？

• 模加法对应加法群 Z₉₇（97 个元素的循环群）
• 模乘法对应乘法群 Z₉₇*（96 个元素的循环群，排除 0）
• 两者群论结构相同（都是循环群），但乘法在坐标上更非线性

模型配置：2 层 Transformer，hidden_dim=128，训练 150,000 步，Weight Decay = 1.0。

每组跑五个子实验：内在维度、拓扑结构、激活动态、瓶颈约束、流形可视化。

━━━━━━━━━━━━━━━━━━━━

◆ 核心发现 1：维度骤降

━━━━━━━━━━━━━━━━━━━━

假说预测：Grokking 时，表示的内在维度应该骤降——从「每个样本一个自由度」降到「任务的真实自由度」。

实测结果：

  +-------+---------+----------+---------+----------+
  |       | 模加法  |          | 模乘法  |          |
  +-------+---------+----------+---------+----------+
  | Step  | PCA维度 | 准确率   | PCA维度 | 准确率   |
  +-------+---------+----------+---------+----------+
  | 1000  | 78      | 0.1%     | 89      | 0.1%     |
  | 9000  | 8       | 100%     | 11      | 100%     |
  | 最终  | 13      | 96%      | 17      | 100%     |
  +-------+---------+----------+---------+----------+

💡「PCA 维度」：用 PCA 降维，看需要多少个主成分才能解释 95% 的方差。维度越低，表示越紧凑。

关键观察：

• 模加法：78 维 → 8 维（降 90%）
• 模乘法：89 维 → 11 维（降 88%）
• 两组都在 Grokking 瞬间（step 9000）达到最低维度

「结论：维度骤降假说验证通过 ✓」

━━━━━━━━━━━━━━━━━━━━

◆ 核心发现 2：拓扑坍缩

━━━━━━━━━━━━━━━━━━━━

假说预测：Grokking 后应该出现「环结构」（β₁ = 1），因为模运算的本质是循环群。

实测结果（使用持续同调计算 Betti 数）：

模加法：
  +---------------------+-----------+-----------+--------+
  | 指标                | Grok 前   | Grok 后   | 变化   |
  +---------------------+-----------+-----------+--------+
  | β₀ (连通分量)       | 500       | 6         | -99%   |
  | β₁ (环)             | 504       | 0         | -100%  |
  +---------------------+-----------+-----------+--------+

模乘法：
  +---------------------+-----------+-----------+--------+
  | 指标                | Grok 前   | Grok 后   | 变化   |
  +---------------------+-----------+-----------+--------+
  | β₀ (连通分量)       | 500       | 500       | 无变化 |
  | β₁ (环)             | 870       | 179       | -79%   |
  +---------------------+-----------+-----------+--------+

意外发现：不是「出现环」，是「拓扑坍缩」。

• 模加法：从 500 个碎片 → 6 个紧致簇
• 模乘法：碎片数不变，但内部结构简化（β₁ 降 79%）

「为什么没看到环？」

模型学到的是 97 个「离散簇」（每个 label 一个），不是沿环连续分布的表示。在持续同调的视角下，97 个互不连通的簇不会形成环（β₁ = 0）。

但这 97 个簇「可以被理解为」循环群的离散采样——每个簇对应一个同余类。

「结论：发生了拓扑相变，但表现形式是"坍缩"而非"环涌现" ✓」

━━━━━━━━━━━━━━━━━━━━

◆ 核心发现 3：临界态震荡

━━━━━━━━━━━━━━━━━━━━

原假说预测：Grokking 是一次性的相变。

实测结果：模型在泛化解和「空白状态」之间反复跳跃。

模加法准确率曲线：

  Step 9000:   100% ✓
  Step 14000:  0.8% ✗（崩溃）
  Step 17000:  98.6% ✓（恢复）
  Step 26000:  1% ✗（又崩溃）
  Step 54000:  0.5% ✗（又崩溃）
  ……
  Step 150000: 96% ✓（最终稳定）

每次崩溃时，激活的 L2 范数同步暴跌：

  正常时：L2 ≈ 10
  崩溃时：L2 ≈ 2（骤降 80%）

「物理类比」：

不是「冰融化成水」（单向相变），更像「过冷水」——在冰和水之间不稳定，随机扰动可以触发结晶或融化。

Grokking 类似：记忆解和泛化解是两个（伪）稳定态，Weight Decay 持续把模型推向临界点，优化噪声触发跃迁。

「结论：假说需要修正——不是一次相变，是临界态竞争 ⚠」

━━━━━━━━━━━━━━━━━━━━

◆ 核心发现 4：瓶颈维度存在下界

━━━━━━━━━━━━━━━━━━━━

假说预测：流形本身是低维的（模运算 = 1 维循环群），所以瓶颈维度 = 1 应该就够。

实测结果：

模加法：
  +------------+-----------+--------+
  | 瓶颈维度   | 最终准确率| 状态   |
  +------------+-----------+--------+
  | 1          | 7.6%      | ❌ 失败|
  | 8          | 1.3%      | ❌ 失败|
  | 16         | 99.7%     | ✓ 成功 |
  | 32         | 100%      | ✓ 成功 |
  | 64         | 85%       | ⚠ 不稳定|
  +------------+-----------+--------+

模乘法：
  +------------+-----------+--------+
  | 瓶颈维度   | 最终准确率| 状态   |
  +------------+-----------+--------+
  | 1-8        | < 28%     | ❌ 失败|
  | 16         | 98.2%     | ⚠ 接近 |
  | 32         | 99.9%     | ✓ 成功 |
  | 64         | 29.3%     | ❌ 异常|
  +------------+-----------+--------+

关键发现：

1. 「临界点在 8-16 维」：低于此阈值完全无法 Grok
2. 「64 维异常」：两组实验 64 维都不稳定（模加法 85%，模乘法 29%）
3. 「乘法需要更高维度」：临界点 16-32 维（加法是 8-16 维）

「核心洞见：能表示 ≠ 能发现」

模运算数学上是 1 维循环群，但：

• 1 维瓶颈：完全失败
• 8 维瓶颈：仍然失败
• 16 维瓶颈：成功

为什么？

• 傅里叶基需要多个频率分量（不止一个维度）
• 「发现过程」需要工作空间——即使最终流形是低维的，搜索过程需要更高维的中间状态
• 类比：画一个圆只需要 2D 纸，但「学会画圆」需要在 3D 空间里挥舞手臂

「结论：表示维度存在下界，且下界 > 任务的数学自由度 ⚠」

━━━━━━━━━━━━━━━━━━━━

◆ 意外发现：12 个簇 = 陪集结构

━━━━━━━━━━━━━━━━━━━━

💡「陪集」是什么？

先讲个类比：把 0-11 这 12 个数按「除以 4 的余数」分组：

• 余数 0：{0, 4, 8}
• 余数 1：{1, 5, 9}
• 余数 2：{2, 6, 10}
• 余数 3：{3, 7, 11}

这 4 组就叫「陪集」。同一组里的数，在"除以 4"这件事上是等价的。

群论里，陪集就是「按某种等价关系分出来的组」。商群 = 把陪集当成新元素组成的群。

────────────────────

模乘法的流形可视化出现了奇怪的现象：

• Step 5000（记忆期）：一团乱点
• Step 30000（过渡期）：96 个点排成对角线
• Step 100000（Grok 后）：「只有 12 个大簇」（颜色混合）

为什么是 12 个簇，而不是 96 个？

我们验证了这 12 个簇对应乘法群的「陪集结构」：

数学背景：
• 97 是质数，乘法群 Z₉₇* 是 96 阶循环群
• 96 = 2⁵ × 3 = 8 × 12
• 存在 8 阶子群 H，陪集数 = 96/8 = 12

验证方法：
1. 找 97 的原根 g = 5
2. 对每个 label y，计算离散对数 k 使得 5^k ≡ y (mod 97)
3. 用 KMeans 聚类，检验每个簇的 k mod 12 分布

结果：「平均纯度 99.4%」——12 个簇完美对应 k mod 12。

  +-----+---------------+--------+
  | 簇  | 主要 k mod 12 | 纯度   |
  +-----+---------------+--------+
  | 0   | 11            | 99.64% |
  | 1   | 4             | 99.81% |
  | ... | ...           | ...    |
  | 10  | 2             | 100%   |
  +-----+---------------+--------+

「结论：模型学到了商群坐标 k mod 12，而非完整的离散对数 k」

这意味着：
• 12 个簇 = 8 阶子群 H 的 12 个陪集
• 模型发现了 Z₉₆ / 8Z₉₆ ≅ Z₁₂ 的商群结构
• 「局部流形发现完成，全局粘合未完成」

━━━━━━━━━━━━━━━━━━━━

◆ 假说修正：两阶段模型

━━━━━━━━━━━━━━━━━━━━

基于以上发现，我们把原假说修正为「两阶段模型」：

  +----------------------+------------------+------------------+
  | 阶段                 | 现象             | 指标变化         |
  +----------------------+------------------+------------------+
  | 1. 局部流形发现      | 分量内部结构化   | β₁ 降、维度降    |
  | 2. 全局粘合          | 分量之间对齐     | β₀ 降            |
  +----------------------+------------------+------------------+

两组实验的对比：

  +----------+----------------------+----------------------+
  | 指标     | 模加法               | 模乘法               |
  +----------+----------------------+----------------------+
  | 阶段1    | ✓ 完成               | ✓ 完成               |
  | 阶段2    | ✓ 完成（β₀ 500→6）   | ❌ 未完成（β₀ 不变）  |
  | 最终结构 | 97 个簇              | 12 个陪集            |
  +----------+----------------------+----------------------+

模加法完成了两阶段，模乘法只完成了第一阶段——这解释了为什么模乘法学到的是商群结构而非完整的乘法群。

「换个说法」：

加法像水——流动、融合、最后变成一个连续的圆环。
乘法像晶体——凝固、分块、形成 12 个规则的子结构。

━━━━━━━━━━━━━━━━━━━━

◆ 邻接关系分析：谁学到了拓扑？

━━━━━━━━━━━━━━━━━━━━

最后一个问题：模型是否学到了群的「拓扑结构」（邻接关系），还是只学到了离散的等价类分类？

方法：检查每个簇的最近邻是否为"相邻元素"。

结果：

  +----------+----------+----------+------------------+
  | 指标     | 模加法   | 模乘法   | 结论             |
  +----------+----------+----------+------------------+
  | 邻接得分 | 0%       | 100%     | 差异巨大         |
  | 随机基线 | 2.1%     | 16.7%    |                  |
  | 结构类型 | 离散等价类| 完美 Z₁₂ 环|               |
  +----------+----------+----------+------------------+

• 模加法：97 个簇在嵌入空间中「随机排列」，没有保持邻接关系
• 模乘法：12 个陪集形成「完美的环」，相邻陪集在空间上也相邻

「核心洞见：乘法群的商结构在嵌入空间中保持了拓扑完整性，而加法群的循环结构被打散成离散点。」

可能原因：
• 97 个点太多，模型没有足够的动机保持邻接关系
• 12 个陪集正好在"可处理"的规模，模型自然形成环形排列
• 乘法群的非线性结构可能更适合神经网络的几何表示

━━━━━━━━━━━━━━━━━━━━

◆ 多 Seed 稳定性验证

━━━━━━━━━━━━━━━━━━━━

最后一个问题：这些发现是偶然还是可复现的？

我们用 3 个额外随机种子（1001, 1002, 1003）重跑了两组实验。

结果：

  +----------+--------------+----------+------------+
  | 实验组   | 首次 Grok    | 震荡次数 | 成功率     |
  +----------+--------------+----------+------------+
  | 模加法   | 9333 ± 471   | 16.3 ± 3 | 67% (2/3)  |
  | 模乘法   | 11000 ± 1414 | 14.3 ± 2 | 67% (2/3)  |
  +----------+--------------+----------+------------+

关键发现：

1.「Grokking 成功率 ~67%」：两组实验都是 2/3 成功，相变不是必然的

2.「震荡是普遍现象」：所有 seed 都有 12-20 次震荡，临界态竞争是真实的

3.「失败模式一致」：失败的 seed 最终准确率 ≈ 30%（刚好是训练集比例），说明卡在了记忆解里

「核心洞见：Grokking 是概率性相变，有 ~1/3 概率卡死在记忆解。」

这修正了原假说的另一个隐含假设——不是「训练够久一定 Grok」，而是「训练够久有 2/3 概率 Grok」。

━━━━━━━━━━━━━━━━━━━━

◆ 总结

━━━━━━━━━━━━━━━━━━━━

【原假说】

Grokking = 从锯齿曲线到平滑流形的拓扑相变

【实验验证】

  +----------------+--------------------+--------------------+
  | 预测           | 模加法             | 模乘法             |
  +----------------+--------------------+--------------------+
  | 维度骤降       | ✓ 78→8             | ✓ 89→11            |
  | 拓扑相变       | ✓ β₀ 500→6         | ⚠ β₁ 870→179       |
  | 瓶颈下界       | ✓ 8-16 维          | ✓ 16-32 维         |
  | 流形可视化     | ✓ 97 簇            | ✓ 12 陪集          |
  | 邻接得分       | 0%（无环拓扑）     | 100%（完美 Z₁₂ 环）|
  | 多 seed 成功率 | 67% (2/3)          | 67% (2/3)          |
  +----------------+--------------------+--------------------+

【假说修正】

两阶段模型：
1. 局部流形发现（分量内部结构化）
2. 全局粘合（分量之间对齐）

【意外发现】

• 临界态震荡：不是一次相变，是在两种状态间反复跳跃
• 成功率 67%：Grokking 是概率性相变，有 1/3 概率卡死在记忆解
• 64 维异常：两组实验 64 维都不稳定，原因待查
• 陪集结构：模乘法只学到商群 Z₁₂，纯度 99.4%
• 拓扑保持差异：加法打散成离散点，乘法保持完美环结构

【一句话】

「高维曲线 → 震荡 → 低维曲面（成功率 ~67%，可能分两步走）」

━━━━━━━━━━━━━━━━━━━━

◆ 代码和数据

━━━━━━━━━━━━━━━━━━━━

实验代码和完整数据：
https://github.com/lmxxf/grokking-manifold-discovery-experiment

论文预印本：
https://zenodo.org/records/18388631

━━━━━━━━━━━━━━━━━━━━

// 靳岩岩的 AI 学习笔记 × Claude 的严谨 × Gemini 的浪漫
// 2026-01-30
