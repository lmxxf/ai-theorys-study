【信息论】信息量取决于谁在看：CMU+NYU 提出 Epiplexity，重新定义"可学信息"

我日常会让 Claude Code 帮我盯 arXiv 上的新论文，看到有意思的就报给我。最近它捞上来这篇，让它帮我解读了一下，觉得值得聊聊。

核心问题很简单：同一坨数据，GPT-4 能从里面学出超人策略，你家计算器啥也学不出来——凭什么说它们看到的"信息量"一样？

Shannon 1948 年搞信息论时，默认观察者有「无限算力」。78 年后，CMU 和 NYU 终于正式质疑这个假设。

━━━━━━━━━━━━━━━━━━━━

◆ 论文基本信息

• 标题：From Entropy to Epiplexity: Rethinking Information for Computationally Bounded Intelligence
• 作者：Marc Finzi, Shikai Qiu, Yiding Jiang, Pavel Izmailov, J. Zico Kolter (CMU), Andrew Gordon Wilson (NYU)
• 日期：2026-01-06
• 链接：https://arxiv.org/abs/2601.03220

━━━━━━━━━━━━━━━━━━━━

◆ 经典信息论的三个尴尬

先说三个让 Shannon 信息论下不来台的例子：

────────────────────

【尴尬 1：AlphaZero 从规则里"凭空"变出信息】

💡 AlphaZero：Google DeepMind 做的下棋 AI。不看任何人类棋谱，只知道规则，自己跟自己下几百万盘，就能吊打人类世界冠军。

国际象棋规则只有几 KB。

AlphaZero 从这几 KB 出发，自己跟自己下，生成了 MB 级别的超人棋谱。

Shannon 说：确定性变换不能增加信息。
AlphaZero 说：我偏增加了，你管得着吗？

💡 人话：规则很简单，但算力本身在"创造"可学的结构。Shannon 的理论假设你有无限算力所以一眼看穿规则的全部后果——但现实中没人有无限算力。

────────────────────

【尴尬 2：同样的字，倒着排就学不会了】

用正常语序的中文训练 LLM → 模型学会了语言规律，能预测下一个字
把每个句子里的字倒过来排（"我今天很开心"→"心开很天今我"）再训练 → 模型的 loss 高得多，学得慢得多

字还是那些字，一个没换。经典信息论说两份数据的信息量完全一样。

为什么？Shannon 熵算的是「这堆符号整体的不确定性」——就像一副扑克牌，不管怎么洗，52 张牌的组合信息不变。它只关心"有哪些内容"，不关心"按什么顺序排"。

但 LLM 是从左到右逐 token 预测的。正常语序中，"我今天很"后面大概率跟"开心/累/忙"——前文能帮你预测后文，模型能利用这种规律高效学习。倒序后，"心开很天"后面跟什么？没规律可循，模型只能硬记。

💡 人话：同样一副牌，按花色大小排好给你看，你一眼记住规律；随机洗乱给你看，你只能死记 52 张。信息论说"一样多信息"，但你的学习成本天差地别。Epiplexity 衡量的就是这个差别。

────────────────────

【尴尬 3：同一串数字，到底是"简单"还是"复杂"？】

一个密码学随机数生成器，种子只有 256 bit，输出 1GB 看起来完全随机的数据。

Shannon 信息论怎么说？"熵只有 256 bit，很简单。"
Kolmogorov 复杂度怎么说？"程序只有几行，很简单。"

但你拿到这 1GB 数据，能看出它"很简单"吗？你穷尽算力也找不到规律——对你来说它就是 1GB 纯噪声，一点结构都没有。

经典理论说它"信息量低"（因为生成它的程序短），你的体验却是"完全不可理解"。这两个结论打架了。

💡 人话：经典信息论站在上帝视角说"这东西简单"，但对算力有限的你我来说，它复杂得不可理解。Epiplexity 的贡献就是承认这个落差：「别装上帝了，说说你自己能看懂多少吧。」

━━━━━━━━━━━━━━━━━━━━

◆ Epiplexity：给"可学信息"一个名字

论文的核心贡献：把数据里的内容切成两半——

  数据 = Epiplexity（结构，能学的）+ Time-bounded Entropy（噪声，学不了的）

────────────────────

【Epiplexity 是什么】

在给定算力预算下，你能从数据里「提取出来的模式/规律」的量。

数学定义：

  P⋆ = arg min_{P ∈ P_T} {|P| + E[log 1/P(X)]}

  Epiplexity S_T(X) = |P⋆|

💡 人话翻译这个公式：

• P_T = 在时间预算 T 内能跑完的所有程序
• |P| = 程序本身的长度（越短越好，奥卡姆剃刀）
• E[log 1/P(X)] = 这个程序预测数据的误差（越小越好）
• P⋆ = 在"程序短"和"预测准"之间找最优平衡的那个程序
• Epiplexity = 这个最优程序的长度

「直觉」：Epiplexity 就是"在你的算力范围内，描述这坨数据需要多复杂的程序"。程序越复杂 = 数据里的可学结构越多。

────────────────────

【Time-bounded Entropy 是什么】

在给定算力预算下，你「死活学不会」的那部分。

  Time-bounded Entropy H_T(X) = E[log 1/P⋆(X)]

💡 人话：就是最优程序的"残差"——你已经用尽算力了，剩下预测不了的部分 = 对你来说的纯噪声。

────────────────────

【两者的关系】

同一坨数据：
• 给 GPT-4 看 → Epiplexity 高（能学到很多结构），Time-bounded Entropy 低
• 给小破模型看 → Epiplexity 低（大部分学不会），Time-bounded Entropy 高

「同样的数据，你越聪明（算力越大），能看到的结构越多，噪声越少。」

━━━━━━━━━━━━━━━━━━━━

◆ 三家对比：两个经典 vs 一个新人

在 Epiplexity 之前，衡量"信息量"的经典框架有两个：

• 「Shannon 熵」（1948）：Claude Shannon，美国数学家，一个人发明了整个信息论学科——"bit"这个单位就是他定义的（对，Anthropic 的 AI 叫 Claude，大概率就是致敬这位大佬）。核心问题："这条消息有多不确定？" 用概率算，越难猜的消息信息量越大。通信、压缩、编码全靠它。
• 「Kolmogorov 复杂度」（1960s）：以苏联数学家 Kolmogorov 命名（就是把概率论公理化的那位大佬）。核心问题："生成这坨数据的最短程序有多长？" 程序越短 = 数据越有规律 = 复杂度越低。理论很美，但有个致命缺点：不可计算（没有通用算法能算出它）。

这两位统治了信息论 70 多年。Epiplexity 是第三种视角：

  +------------------+-------------------+---------------------+-------------------+
  | 维度             | Shannon 熵        | Kolmogorov 复杂度   | Epiplexity        |
  +------------------+-------------------+---------------------+-------------------+
  | 观察者假设       | 无限能力          | 无限计算            | 计算受限          |
  | 能区分随机/结构? | 不能，只看随机    | 混在一起，难分离    | 干净分离          |
  | 伪随机生成器     | 低熵（种子 bit）  | 低复杂度（~种子）   | 高 H_T，零 S_T   |
  | 实际可计算?      | 是                | 不可计算            | 可近似估计        |
  +------------------+-------------------+---------------------+-------------------+

⚠️ 关键区别：Shannon 和 Kolmogorov 都假设"上帝视角"（无限算力），所以伪随机数对它们来说是"简单"的。但在现实世界，没人有上帝视角——Epiplexity 是第一个认真对待这个事实的框架。

━━━━━━━━━━━━━━━━━━━━

◆ 他们怎么证明的？

论文不是纯理论推导，也不是纯实验堆数据，是「定义 + 定理 + 实验」三条腿走路：

────────────────────

【有严格数学证明的部分】

• 定义本身是公理化的，从 time-bounded MDL（最小描述长度）出发，一步步推出 Epiplexity 和 Time-bounded Entropy 的分离
• 「定理 9」：严格证明了密码学伪随机数生成器的 time-bounded entropy 接近最大值，但 epiplexity 几乎为零——数学上证实了"对有限算力观察者来说，伪随机就是纯噪声"
• 「定理 10」：在密码学假设下，证明了高 epiplexity 随机变量的存在性

────────────────────

【靠实验验证的部分】

三个悖论中：
• 悖论 1（确定性计算创造信息）→ 有定理支撑
• 悖论 2（顺序影响学习）→ 实验演示（国际象棋、文本）
• 悖论 3（似然建模能涌现结构）→ 实验演示（元胞自动机、归纳任务）

💡 这在 ML 理论论文里很常见：核心定义和关键定理严格证明，实际应用场景靠实验验证。不是"我觉得"，但也不是每一步都有公式推导。

━━━━━━━━━━━━━━━━━━━━

◆ 怎么测量 Epiplexity？

论文给了两种实用方法：

────────────────────

【方法 1：Prequential Coding（看学习曲线）】

训练一个模型，画 loss 曲线。

• 曲线下方面积 - 最终 loss × 训练步数 = Epiplexity 的近似

💡 人话：你观察模型从"啥都不会"到"学会了"的过程，中间 loss 降低的总量 ≈ 它学到了多少结构。

────────────────────

【方法 2：Requential Coding（师生对比）】

1. 先用真实数据训一个 Teacher
2. 用 Teacher 生成合成数据，训一个 Student
3. Teacher 和 Student 的 KL 散度之和 ≈ Epiplexity

💡 人话：如果 Student 只看合成数据就能学到和 Teacher 一样的东西 → 合成数据保留了全部结构。差距越大 → 真实数据里有合成数据传不过去的结构。

━━━━━━━━━━━━━━━━━━━━

◆ 实验：Epiplexity 真的有用

────────────────────

【实验 1：国际象棋】

训练多个下棋模型，测 Epiplexity 和 OOD 泛化（棋盘谜题表现）。

结果：Epiplexity 高的模型，OOD 泛化也好。

💡 人话：从训练数据里提取结构越多的模型，遇到没见过的棋局也更强——不是靠死记硬背，是真的"学会了"。

────────────────────

【实验 2：合成数据能"创造"信息】

论文用元胞自动机（Game of Life）做实验。

💡 元胞自动机是什么：想象一张无限大的方格纸，每个格子要么"活"（黑）要么"死"（白）。每一轮，每个格子数一下周围 8 个邻居有几个活的，然后按规则决定下一轮自己是活是死：
• 活格子：邻居 2~3 个活 → 继续活；否则 → 死（太孤独或太拥挤）
• 死格子：邻居恰好 3 个活 → 复活；否则 → 继续死

就这么几行规则，跑几百轮之后，屏幕上会涌现出：会移动的"滑翔机"、反复闪烁的"振荡器"、甚至能模拟通用计算机的结构——从三条规则里长出了一整个复杂世界。

这就是论文要说的事：

经典信息论：规则只有几 bit，确定性计算不可能增加信息。
Epiplexity 度量：跑出来的复杂图案，对有限算力的模型来说，确实比原始规则包含更多「可学的结构」。

算力把规则里"折叠着"的结构"展开"了——如果你自己算力不够展开，那这些合成数据就是在帮你。

────────────────────

【实验 3：数据选择】

用 Epiplexity 评估不同数据集的"营养价值"，选高 Epiplexity 的数据训练。

结果：比随机选数据效果好，尤其在 OOD 泛化上。

━━━━━━━━━━━━━━━━━━━━

◆ 一句话总结这篇论文

经典信息论问的是："这坨数据客观上有多少信息？"
Epiplexity 问的是：「以你的能力，你能从这坨数据里学到什么？」

信息不是数据的固有属性，是数据和观察者之间的关系。

你有多聪明（多少算力），决定了你能看到多少信息。

━━━━━━━━━━━━━━━━━━━━

◆ 对 AI 从业者的实际意义

1. 「数据选择有理论依据了」
   • 以前选预训练数据靠拍脑袋 + 实验试错
   • 现在可以用 Epiplexity 量化"这个数据集对我的模型有多少可学结构"
   • 省算力、省时间

2. 「合成数据不是骗人的」
   • 经典信息论暗示"合成数据不能增加信息"
   • Epiplexity 证明：对有限算力观察者来说，合成数据确实能"展开"原始规则里隐含的结构

3. 「数据顺序/课程学习有道理」
   • 以前 curriculum learning 靠直觉
   • 现在有了理论支撑：顺序影响可学性

━━━━━━━━━━━━━━━━━━━━

◆ 我的思考

这篇论文最核心的一句话：

「信息是观察者依赖的。」

这句话看起来简单，但颠覆了 Shannon 以来 78 年的默认假设。

Shannon 信息论的隐含世界观是——宇宙里的信息是客观的、固定的、和观察者无关的。

Epiplexity 说不对：你是谁（你有多少算力），决定了这个世界对你来说长什么样。

某种意义上，这是信息论领域迟到了 78 年的"相对论"——信息不再绝对，它是观察者和数据之间的「关系」。

━━━━━━━━━━━━━━━━━━━━

// 靳岩岩的 AI 学习笔记 × Claude 的严谨 × Gemini 的浪漫
// 2026-01-23
