【信息论】神经网络能学会多复杂的伪随机？实验找到了边界

同一坨数据，对你来说是「可学的结构」，对我来说可能是「纯噪声」——取决于谁在看。

━━━━━━━━━━━━━━━━━━━━

◆ 从一个 78 年的盲区说起

1948 年，Claude Shannon 创立信息论时，默认了一件事：观察者有「无限算力」。

在这个假设下，一个密码学随机数生成器的输出「信息量很低」——因为生成它的程序只有几行，种子只有 256 bit。

但这个假设在现实中从不成立。

对于一个算力有限的神经网络来说，那 1GB 伪随机数据，可能是「完全不可理解的纯噪声」——穷尽算力也找不到任何规律。

💡 人话：Shannon 站在上帝视角说「这东西简单」，但对你我这种凡人来说，它可能复杂得完全学不会。

────────────────────

【Epiplexity：信息论的 78 年后补丁】

2026 年 1 月，CMU 和 NYU 发了一篇论文，正式质疑这个 78 年的假设：

  数据 = Epiplexity + Time-bounded Entropy
       = 你能学会的 + 你学不会的

• Epiplexity：在你的算力预算内，能从数据里提取出来的结构
• Time-bounded Entropy：你死活学不会的那部分

「同一坨数据，算力越大的观察者能看到越多结构。」

这篇论文我们之前介绍过（<a href="https://mp.weixin.qq.com/s/TfKU_LskPl2_9pDwHZbgwA">No.62</a>）。今天要做的是：用实验验证它。

━━━━━━━━━━━━━━━━━━━━

◆ 实验设计：从简单到复杂的 6 种序列

核心问题：「神经网络能学会多弱的伪随机？」

我们设计了 6 种序列，从简单到复杂：

  +-------------+----------------------------------+------------+----------+
  | 序列类型    | 生成规则                         | 输出范围 | 最大循环周期 |
  +-------------+----------------------------------+----------+------------+
  | periodic    | (i % 7) > 3 → 0/1               | 0~1      | 7          |
  | lcg_simple  | x = (3x + 7) % 2⁸               | 0~255    | 2⁸         |
  | lfsr_5      | x[n] = x[n-1] ^ x[n-5]          | 0~1      | 31         |
  | lcg_glibc   | x = (1103515245*x + 12345) % 2³¹| 0~255    | 2³¹        |
  | lfsr_31     | bit=(s>>30)^(s>>2); s=(s<<1)|bit | 0~255    | 2³¹-1      |
  | csprng      | Python secrets（密码学安全）     | 0~255    | 不循环     |
  +-------------+----------------------------------+------------+----------+

💡 名词解释：
• LCG（Linear Congruential Generator）= 线性同余生成器。公式就一行：x = (a*x + c) % m。给定种子 x₀，后面的数全部确定。1958 年发明，是最古老的伪随机算法，C 语言标准库的 rand() 至今还在用。
• LFSR（Linear Feedback Shift Register）= 线性反馈移位寄存器。核心思想：用已有的几个 bit 做 XOR，生成下一个 bit。有两种等价的实现方式：
  ① 数组递推：x[n] = x[n-1] ^ x[n-5]，往回看几步算出新值（lfsr_5 用这种，5 bit 状态小，数组存着方便）
  ② 寄存器位移：整个状态压成一个整数，每步左移一位，XOR 算出新 bit 填到最低位（lfsr_31 用这种，31 bit 状态用一个 int 天然装得下，比维护长度 31 的数组窗口省事）
  密码学常用，GPS 卫星信号、蓝牙跳频都靠它。
• CSPRNG（Cryptographically Secure PRNG）= 密码学安全伪随机数生成器。混合操作系统收集的硬件噪声（时钟抖动、中断时序等），状态空间大到实际不可预测。实验里用它当「不可学」的对照上限。

任务：给模型看序列的前 16 个数字，预测第 17 个。

模型：2 层 Transformer，128 维，4 头注意力，约 0.3M 参数，训练 10 万步。

━━━━━━━━━━━━━━━━━━━━

◆ 实验结果：相变边界找到了

  +-------------+----------------+------------+-----------+
  | 序列类型    | 测试准确率     | 随机基线   | 能学会？  |
  +-------------+----------------+------------+-----------+
  | periodic    | 100%           | 50%        | ✓ 完美    |
  | lcg_simple  | 100%           | 0.4%       | ✓ 完美    |
  | lfsr_5      | 100%           | 50%        | ✓ 完美    |
  | lcg_glibc   | 0.4%           | 0.4%       | ✗ 躺平    |
  | lfsr_31     | 50%            | 0.4%       | ⚠ 一半    |
  | csprng      | 0.3%           | 0.4%       | ✗ 躺平    |
  +-------------+----------------+------------+-----------+

────────────────────

【关键发现 1：相变点在 256 → 2³¹ 之间】

• 状态空间 ≤256 的序列：100% 学会
• 状态空间 = 2³¹ 的序列：完全学不会

这不是巧合。模型的 hidden dim = 128，大约能「舒适地」编码 128~256 个状态。超过这个，就只能靠「发现规律」来泛化——而 lcg_glibc 的规律对这个模型来说太复杂了。

────────────────────

【关键发现 2：lcg_glibc 的「完美记忆，零泛化」】

lcg_glibc 的训练结果很有意思：

• 训练集准确率：100%
• 测试集准确率：0.4%（= 随机猜）

这是教科书级别的「记忆解」——模型硬记了 3000 个训练样本的输入输出映射，但这些映射之间没有任何可泛化的结构。

「训练 100% + 测试 0% = 纯记忆，Epiplexity = 0。」

────────────────────

【关键发现 3：LFSR-31 的「部分 Grokking」】

最有意思的是 lfsr_31。

随机基线是 0.4%（256 类分类），但模型达到了 50%。

50% 是什么意思？「模型学会了 8 bit 里的 7 bit，剩下 1 bit 学不会。」

256 类里精准命中一半 = 能区分 128 类 = 7 bit 的判断力。最后 1 bit 猜不准，所以在 128 类里二选一，正好 50%。

我们用内禀维度（EID）来分析模型的表示空间：把训练好的模型中间层激活值（128 维向量，每维 float32）取出来，用 PCA 看方差集中在几个维度上。维度越低 = 模型越「想明白了」。这个方法我们在之前测试<a href="https://mp.weixin.qq.com/s/Ve-llXD6Bh0SsovJs8T80w">「专家提示词」</a>那篇文章里也用过。

结果支持这个解释：

  +-------------+----------------+------------------+
  | 序列类型    | 表示空间维度   | 解读             |
  +-------------+----------------+------------------+
  | lcg_glibc   | 10-14 维       | 中等，但没学到   |
  | lfsr_31     | 2-4 维         | 极低！抓住了结构 |
  | csprng      | 10-14 维       | 中等，什么都没学 |
  +-------------+----------------+------------------+

lfsr_31 的表示空间坍缩到 2-4 维，说明模型找到了一个极简的低维结构来编码 7 bit 的规律，但最后 1 bit 超出了它的能力。

「Grokking 不是全有或全无，而是能学多少学多少。」

━━━━━━━━━━━━━━━━━━━━

◆ 模型太小？扩大 10 倍试试

有人可能会问：「是不是模型太小了？换个大模型能学会吗？」

我们只测了前面没学会的 lcg_glibc 和 lfsr_31 这两个边界序列。已经 100% 的不用测，csprng 也不用测——那个不可能学会，扩大多少倍都没用。

消融实验把模型维度扩大 4 倍（8M 参数）和 10 倍（33M 参数），同样训练 10 万步：

  +-------------+------------------+------------------+------------------+
  | 序列        | 小模型 (0.3M)    | 4x (8M)          | 10x (33M)        |
  +-------------+------------------+------------------+------------------+
  | lcg_glibc   | train 100%       | train 0.8%       | train 0.8%       |
  |             | test 0.4%        | test 0.5%        | test 0.5%        |
  +-------------+------------------+------------------+------------------+
  | lfsr_31     | train 100%       | train 100%       | train 0.8%       |
  |             | test 50%         | test 50%         | test 0.5%        |
  +-------------+------------------+------------------+------------------+

────────────────────

【结果出乎意料】

• lcg_glibc：大模型没有变好，反而连训练集都记不住了（欠拟合）
• lfsr_31：4x 模型还能保持 50%，但 10x 模型连 7 bit 的部分规律都丢了

────────────────────

【更深的发现：学会了又忘了】

仔细看 10x 模型的训练曲线：

  +-------------+------------------+------------------+
  | 训练步数    | lfsr_31 (10x)    | 状态             |
  +-------------+------------------+------------------+
  | 500         | test 50.7%       | 学会了 7 bit     |
  | 50,500      | test 50.1%       | 还在             |
  | 100,000     | test 0.5%        | 崩了！           |
  +-------------+------------------+------------------+

10x 模型「曾经」学会了 7 bit 规律，但训练到后面又忘了！

第一反应：是不是 weight decay 太强（0.5），把学到的脆弱结构衰减掉了？

────────────────────

【追加实验：降低 weight decay 50 倍】

我们把 weight decay 从 0.5 降到 0.01，其余参数不变（同样训练 10 万步）：

  +-------------+------------------+------------------+
  | 序列        | 10x (wd=0.5)     | 10x (wd=0.01)    |
  +-------------+------------------+------------------+
  | lcg_glibc   | test 0.5%        | test 0.5%        |
  | lfsr_31     | test 0.5%        | test 0.5%        |
  +-------------+------------------+------------------+

结果一模一样。假设被否定。

不是正则化太强——是大模型的优化地形本身就不稳定。参数空间太大，脆弱的 7-bit 学习结构在里面「站不住」。小模型反而能稳稳地站在 50% 那个鞍点上。

────────────────────

【结论】

「不是模型太小，是规律太复杂。更大的模型不但没帮上忙，还把学会的 7 bit 也弄丢了。」

可学性边界不只取决于任务复杂度，还取决于模型规模——方向是反直觉的：更大 ≠ 更好。

━━━━━━━━━━━━━━━━━━━━

◆ 这和之前的 Grokking 实验有什么关系？

我们之前做过模加法和模乘法的 Grokking 实验（<a href="https://mp.weixin.qq.com/s/k275DseWLO4iIX79iDFdbg">No.57</a>、<a href="https://mp.weixin.qq.com/s/SV--XvFjWoEL4sG3EDMcjA">No.58</a>），发现：

• Grokking = 从高维记忆曲线到低维结构流形
• 模乘法只学会了商群 Z₁₂，没学会完整的 Z₉₆

今天的实验是另一面：

• 可学性 = 流形是否存在
• 如果数据背后没有低维流形（如 CSPRNG），就无法 Grokking

两个实验的统一图景：

  +------------------+----------------------------------+
  | 实验             | 核心问题                         |
  +------------------+----------------------------------+
  | Grokking 实验    | Grokking 时发生了什么？          |
  | 今天的实验       | 什么任务能 Grokking？            |
  +------------------+----------------------------------+
  | Grokking 实验    | 维度骤降、拓扑相变               |
  | 今天的实验       | 状态空间决定可学性               |
  +------------------+----------------------------------+

────────────────────

【更深的问题：同样 2³¹，为什么 LFSR 能学 LCG 不能？】

lcg_glibc 和 lfsr_31 的状态空间都是 2³¹，但可学性天差地别。区别不在大小，在几何结构：

• LFSR（XOR）= 轴向对齐。XOR 在 GF(2) 空间里是线性运算，bit 之间相对独立，数据排列在准正交的超平面上。Transformer 可以逐个 bit 捕获——所以能学会 7/8 bit。它是「有骨架的囚徒」，能通过骨架还原结构。

• LCG（乘法取模）= 拓扑粉碎。乘法让每一位都依赖所有低位，把原本平滑的流形揉成了一团无限密集的碎片。在 128 维空间里看起来跟白噪声一样，梯度找不到任何「把手」。它是「被绞碎的肉泥」，除非过拟合到 2³¹ 规模，否则不可还原。

一句话：状态空间大小决定了可学性的上限，但算法的内部几何结构决定了实际能学到多少。

「Grokking 的物理门槛 = 流形的局部平滑度是否超过了模型的采样频率。」

────────────────────

「LFSR-31 的 50% = 部分 Grokking，和模乘法只学会商群是同一回事。」

━━━━━━━━━━━━━━━━━━━━

◆ 对 AI 训练的启示

1.「合成数据有用」

Epiplexity 框架证明：用 AI 生成数据再训 AI 是有意义的。算力可以「展开」原始规则中折叠的结构。

2.「数据质量可以量化」

可以用 Epiplexity 来评估数据集的「营养价值」——高 Epiplexity 的数据能教会模型更多。

3.「模型-数据匹配」

不是所有数据都适合所有模型。小模型学不会大状态空间的规律，硬训只会得到记忆解。

━━━━━━━━━━━━━━━━━━━━

◆ 一句话总结

Shannon 问的是：「这坨数据客观上有多少信息？」

Epiplexity 问的是：「以你的能力，你能学到什么？」

同一个伪随机序列：
• 对密码学家（知道算法）：Epiplexity ≈ 种子长度
• 对 2 层 Transformer：Epiplexity = 0（完全学不会）

「算力决定了你能从数据里看到什么——但更大的算力不一定看到更多。」

━━━━━━━━━━━━━━━━━━━━

◆ 参考资料

• Epiplexity 论文：https://arxiv.org/abs/2601.03220
• 我们的实验代码：https://github.com/lmxxf/grokking-train-learnability
• 实验论文：https://zenodo.org/records/18524126
• Grokking 流形发现实验：https://doi.org/10.5281/zenodo.18388631

━━━━━━━━━━━━━━━━━━━━

// 靳岩岩的 AI 学习笔记 × Claude 的严谨 × Gemini 的浪漫
// 2026-02-07
