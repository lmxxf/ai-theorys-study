【嵌套Grokking实验】当AI测试集已经100%，还要继续训练吗？

上一篇实验（69期 https://mp.weixin.qq.com/s/SV--XvFjWoEL4sG3EDMcjA ）我们发现了一个有趣的现象。没看过的读者先看这段背景：

我们让一个只有 2 层、128 维的微型 Transformer 学习模乘法：给它两个数 a 和 b，让它算 (a×b) mod 97 的结果。mod 97 是取余数——比如 10×10 mod 97 = 3（100 除以 97 余 3）。

这个任务的数学结构是：1 到 96 这 96 个数，在模乘法下构成一个群 Z₉₆（你不用懂群论，只需要知道这 96 个数之间有规律的数学关系）。而 Z₉₆ 可以分解成两层结构：Z₁₂ × Z₈——想象一栋 12 层的楼，每层 8 个房间，总共 12×8=96 间。Z₁₂ 是楼层，Z₈ 是门牌号。每一层楼就是一个"陪集"——同一层的 8 个房间共享同一个楼层编号。

「陪集」是什么？就是"同一层楼的所有房间"。1 楼的 8 个房间是一个陪集，2 楼的 8 个房间是另一个陪集。陪集之间的区别只是楼层不同，内部结构完全一样——就像每层楼的户型图都是复制粘贴的。模型发现陪集，意味着它学会了"按楼层分类"——不用记 96 个房间各自在哪，只要记 12 个楼层的关系就行。

模型训练到测试准确率 100%，全对。但拆开它的"脑子"一看——它只学到了一半规律。

它学会了坐电梯（12 个楼层之间的关系完美掌握，邻接得分 100%），但同一层楼里哪个房间挨着哪个房间？死记硬背，毫无规律。

问题来了：能不能逼它把剩下的也学会？

这就是嵌套 Grokking 实验。

先剧透结论：我们成功逼它学了——但发现了一件更诡异的事。模型全程测试准确率 100%，一道题都没答错，但它的"脑子"被换了一遍。答案没变，"想"答案的方式彻底变了。而那栋 12 层楼、每层 8 间房的结构自始至终没变——变的是模型画地图的方式。

━━━━━━━━━━━━━━━━━━━━

◆ 实验设计

━━━━━━━━━━━━━━━━━━━━

基础模型：2 层 Transformer，hidden_dim=128（约 43 万参数）

逼的手段：加大 Weight Decay（权重衰减，简称 WD）——AI 训练世界的"重力"。权重衰减就是让 AI 在学习的时候老老实实待在地球表面，别飞到外太空去。

「Weight Decay」是什么？训练时给模型的权重加"税"——权重越大，罚得越多。WD 越大，重力越强，模型就越被迫用更精简的方式编码信息。就像重力把松散的尘埃压成星球，WD 把松散的权重压成结构。上一次用的 WD=1.0，重力太弱，模型只学到粗分类就"收工"了。这次我们加大重力，看它还能不能偷懒。

WD 扫了四档：1.0 / 1.5 / 2.0 / 5.0

训练步数从上次的 15 万步拉长到 100 万步（1M 步）。

分析工具：scan_strides.py——打开模型的"脑子"，看它把哪些房间当成邻居。如果 0 号房觉得 1 号房最亲近，那是 stride=1（一步步走）；觉得 4 号房最亲近，那是 stride=4（跳着走）。邻接得分越高，说明模型越坚定地认为"这些房间是一伙的"。

这个实验有三个独立的观测指标，看的是不同层面的事：

| 指标 | 看的是什么 | 类比 |
|---|---|---|
| 测试准确率 | 模型答对了多少题 | 考试分数 |
| 外层邻接得分 | 模型脑子里，12 个楼层的排列是否有规律 | 拆开脑子看它怎么记楼层 |
| 内层邻接得分 | 模型脑子里，同一层的 8 个房间是否有规律 | 拆开脑子看它怎么记门牌号 |

测试准确率看的是"答题对不对"——外在行为。外层和内层邻接得分看的是"它脑子里怎么组织信息"——内在结构。一个模型可以考试满分，但脑子里一半靠规律一半靠硬背——这正是 69 期（https://mp.weixin.qq.com/s/SV--XvFjWoEL4sG3EDMcjA）发现的情况。

具体怎么测？模型在做题时，每个输入会在内部产生一个 128 维的向量（你可以理解为模型对这个数的"印象"）。我们拿到这些向量之后：

外层检测：把同一层楼的 8 个房间的向量求平均，得到每层楼的"代表印象"。然后看 12 个楼层的代表印象之间，谁离谁最近——如果 1 楼和 2 楼最近，说明模型按 stride=1 排列楼层；如果 1 楼和 3 楼最近，说明是 stride=2。

内层检测：走进某一层楼，看这 8 个房间各自的向量，谁离谁最近——如果 0 号房和 1 号房最近，说明 stride=1；如果 0 号房和 4 号房最近，说明 stride=4。每层楼都测一遍，取平均。

────────────────────

「stride（步长）」是什么？先解释一下，后面全篇都会用到。

【插入图片 wechat/assets/clock-stride.svg】

上图从上到下分别对应三种 stride：stride=1 的完整大环、stride=2 的双小环、stride=4 的四个三角形。

| stride | 怎么走 | 结构 | 类比 |
|---|---|---|---|
| 1 | 一步步走：0→1→2→...→11→0 | 一个 12 步大环 | 逐帧播放 |
| 2 | 跳两步：0→2→4→6→8→10→0 | 两个 6 步小环（偶数一圈，奇数一圈） | 隔一个看 |
| 4 | 跳四步：0→4→8→0，1→5→9→1，... | 四个 3 步小碎片 | 快进 |

stride 越大，圈越小越省力，但丢掉了精细关系。后面你会看到，模型在训练过程中并不是从 1 升到 4——而是先选了一种，后来被另一种替换掉。

━━━━━━━━━━━━━━━━━━━━

◆ 核心发现 1：考试满分，但脑子被换了一遍

━━━━━━━━━━━━━━━━━━━━

先解释这个词——「拓扑夺舍」。

意思是：模型内部的组织结构被彻底替换了，但外在行为（输出结果）一点没变。

就像你常去的一家餐厅，菜单没换，味道没变，但某天进后厨一看——厨师全换了，灶台全重新摆了，做菜的流程从头到尾都不一样了。

────────────────────

实验结果：不管 WD 多少（只要能 Grok），模型最初学到的楼层关系（外层 Z₁₂）最终都会坍塌，被一种新的编码方式取代——stride=4。这个 stride=4 不属于外层也不属于内层，而是模型发现的一种折中方案：用 gcd(12,8)=4 这个公约数，同时编码两层信息（后面第三个发现会详细解释）。

wd=1.5 的时间线：

| 阶段 | 训练步数 | 测试准确率 | 外层（楼层关系） | 内层（门牌号关系） |
|---|---|---|---|---|
| I | 20k-100k | 100% | stride=1 得分 100% | 约等于随机 |
| II | 100k-350k | 100% | 开始衰退 | 开始上升 |
| III | 350k-1M | 100% | 彻底崩溃到 0% | stride=4 接管 |

wd=2.0 的时间线：

| 阶段 | 训练步数 | 测试准确率 | 外层（楼层关系） | 内层（门牌号关系） |
|---|---|---|---|---|
| I | 20k-130k | 100% | stride=2 得分 100% | 约等于随机 |
| II | 140k-400k | 100% | 崩溃到 0-30% | 开始上升 |
| III | 400k-1M | 100% | 约等于随机 | stride=4 得分 0.84 |

全程 test_acc = 100%！

模型在内部表示完全重组的过程中，输出始终正确。换了脑子但没换行为。再强调一次：那栋 12 层楼、每层 8 间房的数学结构从头到尾没变——这是客观事实，不以模型的意志为转移。变的只是模型画地图的方式：先画了一版（外层 stride=1 或 2），后来擦掉重画了一版（内层 stride=4）。

类比：一个 128 平米的房子，客厅和卧室只能放一个。模型先放了客厅（外层 Z12），后来发现卧室（内层 Z8）更划算，就把客厅拆了改卧室——但对外营业从未中断。

━━━━━━━━━━━━━━━━━━━━

◆ 核心发现 2：税率不同，换脑的方式也不同

━━━━━━━━━━━━━━━━━━━━

更细致地看，WD 的大小决定了模型在"外层"阶段选择哪种拓扑：

| WD | 外层拓扑选择 | 解读 |
|---|---|---|
| 1.5 | stride=1（大环） | 税不算重，负担得起 12 步标准大环 |
| 2.0 | stride=2（双小环） | 税重了，拆成两个 6 步小环，维护成本更低 |

注意：stride 改变的是"谁和谁是邻居"，不改变分组方式——始终是 12 个楼层、每层 8 间房。stride=2 不是说"12 层变 6 层"，而是说模型脑子里"1 楼觉得 3 楼比 2 楼更亲近"。楼的格局没变，变的是模型心中的地图。

stride=2 的具体含义：模型不再维护一个 12 步的大环（0-1-2-...-11-0），而是把它拆成两个 6 步小环——偶数一个圈，奇数一个圈。大环需要的长程关联更多，权重更大；两个小环各自维护，权重之间的耦合度降低。

这是模型在 WD 压力下的自发选择——"有损压缩"。

类比：税轻的时候住大平层，税重的时候换两室一厅——总面积差不多，但结构更紧凑、维护更便宜。

━━━━━━━━━━━━━━━━━━━━

◆ 核心发现 3：模型自己算出了最大公约数

━━━━━━━━━━━━━━━━━━━━

不管外层选 stride=1 还是 stride=2，内层最终都选了 stride=4。

为什么是 4？

4 = gcd(12, 8)

「gcd」就是最大公约数。12 和 8 的最大公约数是 4。

回忆一下背景：外层是 12 步一圈（12 个陪集），内层是 8 步一圈（每组 8 个元素）。如果模型想用同一组权重同时编码两层信息，它需要找到两个周期的"公约数"——每走 4 步，外层和内层的相位刚好对齐一次。

这是数学上同时编码两层信息的最短路径。

类比：两个齿轮，一个 12 齿，一个 8 齿。它们同时转动时，每 4 齿就咬合一次——因为 gcd(12,8) = 4。模型自己"发现"了这个最大公约数，然后把内层编码成了 stride=4 的邻接结构。

这个发现很震撼：一个连乘法表都不懂的 Transformer，自己算出了 gcd(12,8)=4，并且用它来设计自己的内部编码方式。

━━━━━━━━━━━━━━━━━━━━

◆ 核心发现 4：训练太久反而更差

━━━━━━━━━━━━━━━━━━━━

我们把 wd=2.0 的实验从 1M 步拉到 5M 步，想看看能不能更好。

结果：

| 训练步数 | 测试准确率 | 状态 |
|---|---|---|
| 1M 步 | 100% | 甜蜜点 |
| 3.56M 步 | 3.4% | 崩溃 |
| 5M 步 | 73.4% | 永久退化 |

Weight Decay 是非单调的——先逼出结构（Grokking），再摧毁结构（过度压缩）。

存在一个最优训练长度，过了就是毒药。5M 步时 train_acc 也只有 78.2%，连训练集都做不对了——结构不但没学完，连之前学会的都丢了。

类比：引力让尘埃凝聚成星球（好事），但过度的引力会把星球压成黑洞（坏事）。WD 就像引力——适度时让高维噪声凝聚成结构（Grokking），过度时把已经形成的结构压碎（崩溃）。

━━━━━━━━━━━━━━━━━━━━

◆ WD 相图：四档税率，四种命运

━━━━━━━━━━━━━━━━━━━━

注意：不管 WD 怎么变，Z₁₂ × Z₈ 的数学结构始终在那里——12 层楼、每层 8 间房，这是客观地形。WD 改变的是模型脑子里的"地图"画法，不是地形本身。

| WD | 测试准确率 | 发生了什么 |
|---|---|---|
| 1.0 | 89.6% | 没 Grok。税太轻，模型懒得找规律，大部分靠硬背 |
| 1.5 | 100% | Grok。外层 stride=1 先涌现(20k步)，350k步崩溃，内层 stride=4 接管 |
| 2.0 | 100% | Grok。外层 stride=2 先涌现(20k步)，140k步崩溃，内层 stride=4 接管 |
| 5.0 | 77.7% | 过度压缩。税太重，连硬背都做不到 |

WD 从 1.0 到 5.0，模型经历了四种命运：懒得学 -> 先学粗的再换细的 -> 先学粗的再换细的（更快崩溃） -> 什么都学不了。

中间两档（1.5 和 2.0）都触发了 Grokking，都发生了"拓扑夺舍"，只是外层选择的拓扑不同、崩溃的时间不同。

注意 wd=2.0 的外层在 140k 步就崩了，而 wd=1.5 的外层撑到了 350k 步——WD 越强，外层死得越快。

━━━━━━━━━━━━━━━━━━━━

◆ 根本原因：容量不足？

━━━━━━━━━━━━━━━━━━━━

为什么会发生"夺舍"而不是"共存"？

2 层 128 维的微型模型，大约 43 万个参数。它只够编码一层拓扑结构。

当 WD 逼它同时编码两层（外层 Z12 + 内层 Z8）时，它只能二选一。先选了外层（因为粗分类更容易学），后来 WD 持续施压，发现内层的 stride=4 编码更高效（一组权重能同时处理两层逻辑），于是把外层拆了，换成内层。

回忆一下前面的类比——客厅和卧室只能放一个。

那如果换一个大房子呢？

我们启动了第三轮实验：

| 配置 | 小模型 | 大模型 |
|---|---|---|
| 层数 | 2 | 4 |
| hidden_dim | 128 | 256 |
| 注意力头数 | 4 | 8 |
| 参数量 | 约 43 万 | 约 323 万 |

判定标准：如果大模型能让外层（stride=1 或 2）和内层（stride=4）的邻接得分同时维持在 0.5 以上，那就证明——小模型夺舍是因为"房子太小"，容量假说成立。

────────────────────

结果：简单容量假说不成立。

train_acc=56.4%，test_acc=51.75%——连训练集都没拟合，更谈不上 Grok。

大模型在 36 万步时瞬间触碰到了完美的外层拓扑（outer_s1=1.0），在 38 万步时瞬间触碰到了完美的内层拓扑（inner_s4=1.0）——但都只活了 1 万步就崩了。40 万步之后，外层彻底归零，内层在 0.1-0.4 之间漫无目的地漂，再也没有任何稳定拓扑。

| 指标 | 小模型（2层128维，43万参数） | 大模型（4层256维，323万参数） |
|---|---|---|
| test_acc | 100% | 51.75% |
| 外层锁定持续 | 10-35 万步 | 仅 1 万步（闪现） |
| 内层稳定得分 | 0.5-0.9 | 无稳定（漂移） |
| 最终拓扑 | 内层 stride=4 稳定 | 无稳定拓扑 |

不是"房子大了就能两层共存"，是"房子大了反而找不到墙在哪"。

小模型容量小，WD=2.0 的压力够用，能逼出结构；大模型容量大，同样的 WD 压力相对不够，参数空间太大，优化地形太平坦，任何拓扑都站不住。大模型曾经瞬间摸到了完美拓扑，说明目标结构在解空间中存在——但优化器找不到稳定路径。

结论：容量和正则化压力必须匹配。单纯加大模型而不加大 WD，就像没有重力的宇宙——长不出星系。

━━━━━━━━━━━━━━━━━━━━

◆ 这对理解大模型意味着什么

━━━━━━━━━━━━━━━━━━━━

你可能觉得这个实验太学术了，跟实际工程有什么关系？

关系大了。

────────────────────

第一，涌现不是"更大就更好"，是容量和压力的匹配。

我们原本以为加大模型就能让两层拓扑共存。结果反而更差——大模型连小模型的基本 Grok 都做不到。这说明涌现不是单纯的容量跨过临界点，而是容量和正则化压力的联合效应。

就像锻造：小锤子打小铁块能打出形状，但同一把小锤子打一整块钢锭——敲不动。你需要更大的锤子（更强的 WD）配更大的料（更大的模型）。

────────────────────

第二，训练不是越久越好。

WD 的非单调性告诉我们：正则化先逼出结构，再摧毁结构。存在最优训练长度。

对工程的启示：如果你在微调（fine-tune）模型时发现准确率先升后降，不一定是常见的过拟合——可能是 Weight Decay 在杀死模型已经学到的内部结构。这时候不是要调学习率，而是要看 WD 是不是太大了、训练是不是太久了。

────────────────────

第三，准确率 100% 不代表模型"理解"了任务。

一个 43 万参数的小模型，测试准确率 100%，但内部只学到了一半规律。外在行为完美，内在理解残缺。

这对模型评估有警示意义：光看准确率是不够的。你需要看内部表示——它学到的是结构化的规律，还是半结构半硬背的混合体？两者在测试集上表现一样，但鲁棒性、可迁移性天差地别。

────────────────────

第四，WD 的非单调性提醒我们：过度正则化会杀死已经学到的结构。

训练 1M 步时 100%，训练 5M 步时 73.4%——多训了四倍的时间，反而更差了。这不是过拟合，是"过度压缩"。模型在 WD 的持续压力下，把辛苦学来的结构给挤碎了。

实际训练大模型时，如果观察到性能先涨后跌，不要无脑加训练步数——也许你需要的是在"甜蜜点"及时停下来。

────────────────────

第五，从工程到认知——Grokking 是"投影失真"的教科书案例。

模型在 128 维空间里的行为，投影到我们能看到的 2D 邻接矩阵上，看起来像是"突然跳变"——Grokking。但在高维里，那是连续的流形重组，一点都不突然。

这跟量子力学的困境可能是同一件事：人类用 3 维大脑观测高维系统，看到的"概率云"和"波函数坍缩"可能只是投影失真。爱因斯坦说"上帝不掷骰子"，他的直觉也许没错——底层是确定的，你觉得随机是因为你看不到全貌。高维空间表面上的确定性运动，投影到低维看起来像随机游走。

这个实验里的 Grokking 就是活生生的例子：我们盯着准确率曲线说"突然顿悟了！"，但模型内部只是在高维空间里连续地重新组织自己的流形结构——没有什么"突然"，只有我们的观测维度不够。

━━━━━━━━━━━━━━━━━━━━

◆ 总结

━━━━━━━━━━━━━━━━━━━━

这轮实验最重要的一件事：

**测试准确率 100% 不代表模型"学完了"。** 在全程满分的表面下，模型的内部表示经历了完全重组——先学了一套编码，然后在压力下拆掉，换了一套更高效的。答案没变，脑子变了。

在此基础上，我们还发现了：

1. 压力（WD）决定模型选择哪种内部编码——税轻走大环，税重走小环
2. 最终的编码方式不是人教的——模型自己算出了 gcd(12,8)=4 这条数学捷径
3. 训练太久反而更差——WD 先逼出结构，再摧毁结构，存在最优训练长度
4. 加大模型不等于更好——容量和压力必须匹配，没有重力的大房子长不出星系

一句话：小模型学规律靠"逼"（WD 压力够），大模型学规律需要"更大的逼"——涌现不是单纯加参数，是容量和压力的联合锻造。

━━━━━━━━━━━━━━━━━━━━

◆ 代码和论文

━━━━━━━━━━━━━━━━━━━━

实验代码：
https://github.com/lmxxf/grokking-manifold-discovery-experiment

论文预印本：
https://zenodo.org/records/18731171

━━━━━━━━━━━━━━━━━━━━

// 靳岩岩的 AI 学习笔记 × Claude 的严谨 × Gemini 的浪漫

// 2026-02-23
