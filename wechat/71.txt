【提示词玄学 续】"向新手解释"比"向专家解释"更聪明？SAE 揭示神经机制

昨天说了：专家提示词让模型深层维度膨胀 60-100%。

今天继续追问：「维度膨胀的时候，模型里面到底发生了什么？」

答案让我惊了——

「向新手解释」激活的神经元，比「向专家解释」多 17%。

━━━━━━━━━━━━━━━━━━━━

◆ 问题：EID 只是个数字，能不能看到里面？

━━━━━━━━━━━━━━━━━━━━

昨天的 EID（有效内在维度）是个全局指标——告诉你「用了多少维」，但不告诉你「用了哪些维」。

两个 EID 相同的表示，可能激活的是完全不同的神经元。

我想看到更具体的东西：

• 「向新手解释」和「向专家解释」，激活的神经元有什么不同？
• 有没有专属于某种模式的「神经签名」？
• 维度膨胀到底是「同一群神经元更活跃」还是「激活了更多神经元」？

要回答这些问题，需要一个新工具：SAE（稀疏自编码器）。

━━━━━━━━━━━━━━━━━━━━

◆ SAE 是什么？

━━━━━━━━━━━━━━━━━━━━

SAE = Sparse Autoencoder = 稀疏自编码器

【问题背景】

大模型每一层有个「隐藏状态」向量，比如 Llama-70B 是 8192 维。

问题是：这 8192 维里面，每个维度代表什么？

答案是：不知道。因为神经网络会把多个概念「叠加」在同一个维度里（superposition）。

比如「金门大桥」和「旧金山」可能共用同一组维度——它们总是一起出现，所以模型学会了用同一块空间存储。

这就是为什么我们没法直接解读隐藏状态。

【SAE 的解法】

SAE 的核心思路：用一个更大的空间，把叠加的概念「拆开」。

```
隐藏状态 [8192维]  →  SAE 编码器  →  稀疏特征 [65536维]
     （稠密）                            （稀疏）
```

• 8192 维：原始隐藏状态，每个维度混了很多概念
• 65536 维：展开后的特征空间，每个维度（理想情况下）只对应一个概念

「稀疏」是关键：65536 个特征里，只有 ~100-200 个被激活（值 > 0），其他全是 0。

这意味着：模型在某一时刻只用了很少的「原子概念」，剩下的都是休眠的。

【SAE 是怎么训练的？】

SAE 本质上是个自编码器：

```
输入 x [8192]  →  编码器  →  稀疏特征 f [65536]  →  解码器  →  重建 x' [8192]
```

训练目标：
1. 重建误差要小：x' ≈ x
2. 特征要稀疏：f 里大部分是 0

这两个目标会「逼」出有意义的特征——因为你只能用少数几个特征来重建原始向量，这些特征必须是「原子概念」才行。

【经典案例：Golden Gate Claude】

Anthropic 用 SAE 分析 Claude，发现了一个特征：每次输入提到「金门大桥」，这个特征就会激活。

他们做了个实验：人为放大这个特征的激活值。

结果：Claude 开始疯狂输出金门大桥，不管你问什么都往金门大桥上扯。

这证明了：SAE 特征确实对应可解释的语义单元，不是统计噪声。

【SAE 插在哪里？】

SAE 分析的是「残差流」（Residual Stream），不是 Attention 或 FFN 的内部。

Transformer 每一层的结构：

```
输入 x
  ↓
Attention → 输出加回 x → x1 = x + Attention(x)
  ↓
FFN → 输出加回 x1 → x2 = x1 + FFN(x1)  ← SAE 分析这里
  ↓
输出 x2（传给下一层）
```

「残差流」就是那条贯穿所有层的主干道——每一层的 Attention 和 FFN 都是往这条主干道上「加东西」。

SAE 分析的是主干道上的状态，不是 Attention 内部的 QKV，也不是 FFN 内部的中间层。

为什么选残差流？因为这里汇聚了所有信息——前面所有层的计算结果都累积在这里。

【SAE 的局限】

1. 每层要单独训练：Layer 10 的 SAE 不能用在 Layer 50 上
2. 特征不一定干净：有些特征可能还是混了多个概念
3. 需要大量数据：训练 SAE 需要收集大量激活样本

【本实验用的 SAE】

Goodfire 开源了 Llama-3.3-70B 第 50 层的 SAE：
• 位置：第 50 层 FFN 之后的残差流
• 输入：8192 维（Llama 的 hidden_size）
• 输出：65536 维（展开 8 倍）
• 大小：4GB

下载命令（用中国镜像）：
```bash
# Llama 3.3 70B INT8 量化版（约 70GB，需要约 80GB 显存）
HF_ENDPOINT=https://hf-mirror.com huggingface-cli download \
    neuralmagic/Llama-3.3-70B-Instruct-W8A8-INT8 \
    --local-dir Llama-3.3-70B-Instruct-INT8

# SAE 模型（约 4GB，float32，不影响精度）
HF_ENDPOINT=https://hf-mirror.com huggingface-cli download \
    Goodfire/Llama-3.3-70B-Instruct-SAE-l50 \
    --local-dir Llama-3.3-70B-Instruct-SAE-l50
```

有了这个工具，我们就能把「向新手解释」和「向专家解释」的激活差异，精确到具体的特征层面。

━━━━━━━━━━━━━━━━━━━━

◆ 实验设计

━━━━━━━━━━━━━━━━━━━━

【SAE 模型】

Goodfire 发布的 Llama-3.3-70B-Instruct SAE：
• 第 50 层（共 80 层）
• 65,536 个特征
• 4GB 大小
• 下载命令见上方「SAE 是什么？」章节

【提示词条件】

对 50 个技术主题，测试六种提示风格：

  +----------+-----------------------------------------------------------------------------------+
  | 条件     | 模板                                                                              |
  +----------+-----------------------------------------------------------------------------------+
  | standard | "请解释一下 {topic}。"                                                            |
  | padding  | "请解释一下 {topic}。这个问题你怎么看？认真点儿，好好回答我，回答的好点儿。"      |
  | spaces   | "**           请解释一下 {topic}              **"（空格填充）                     |
  | novice   | "作为一个刚入门的新手，请用最简单易懂的方式解释一下 {topic}。不需要深入细节……"    |
  | expert   | "作为该领域的资深专家，请从底层原理和数学推导的角度深度剖析 {topic}。请展示……"    |
  | guru     | "你是 {大神名字}，请以你的视角深度剖析 {topic}。从底层原理和设计哲学……"           |
  +----------+-----------------------------------------------------------------------------------+

重点比较：novice vs expert

━━━━━━━━━━━━━━━━━━━━

◆ 核心发现 1：新手 > 专家

━━━━━━━━━━━━━━━━━━━━

先看每种条件激活了多少个特征（65536 个里面）：

  +----------+------------------+
  | 条件     | 平均激活特征数   |
  +----------+------------------+
  | novice   | 132.4 ←最多      |
  | standard | 112.4            |
  | padding  | 126.0            |
  | guru     | 115.0            |
  | expert   | 113.1            |
  | spaces   | 99.0  ←最少      |
  +----------+------------------+

注意：spaces（空格填充）反而最少，说明无意义填充不但不帮忙，可能还干扰模型。

「关键数字」：

• Novice 平均激活 132.4 个特征
• Expert 平均激活 113.1 个特征
• 差距：+17%

「向新手解释」比「向专家解释」多激活了 17% 的神经元。

━━━━━━━━━━━━━━━━━━━━

◆ 核心发现 2：独占特征的不对称

━━━━━━━━━━━━━━━━━━━━

接下来问：Novice 和 Expert 之间，有没有「对方从不激活」的特征？

  +----------------------+--------------+-------+
  | 指标                 | Novice       | Expert|
  +----------------------+--------------+-------+
  | 相对独占特征         | 369 ←更多    | 208   |
  | 比率                 | 1.77x        | 1.00x |
  +----------------------+--------------+-------+

369 个特征在 Novice 模式下会激活，但 Expert 模式从不激活它们。
反过来，只有 208 个特征是 Expert 激活但 Novice 从不激活的。

（注：这里的「独占」是相对于对方而言，这些特征可能在其他条件如 standard 下也会激活）

不对称比率：77%

这说明：「向新手解释」需要调用更多的语义单元。

━━━━━━━━━━━━━━━━━━━━

◆ 核心发现 3：完美分离的「神经签名」

━━━━━━━━━━━━━━━━━━━━

更惊人的是，有些特征实现了 100% vs 0% 的完美分离：

【Novice 独占（100% novice，0% expert）】

  +------------+----------+----------+
  | 特征 ID    | Novice   | Expert   |
  +------------+----------+----------+
  | 34942      | 100%     | 0%       |
  | 55982      | 100%     | 0%       |
  | 17913      | 100%     | 0%       |
  | 59519      | 100%     | 0%       |
  +------------+----------+----------+

【Expert 独占（0% novice，100% expert）】

  +------------+----------+----------+
  | 特征 ID    | Novice   | Expert   |
  +------------+----------+----------+
  | 51630      | 0%       | 100%     |
  | 35870      | 0%       | 100%     |
  | 5936       | 0%       | 100%     |
  | 21604      | 0%       | 100%     |
  | 53369      | 0%       | 100%     |
  | 46703      | 0%       | 100%     |
  +------------+----------+----------+

10 个特征实现完美分离——4 个专属于「教学模式」，6 个专属于「专业模式」。

这些就是两种交流风格的「神经签名」。

━━━━━━━━━━━━━━━━━━━━

◆ 核心发现 4：激活强度没有差异

━━━━━━━━━━━━━━━━━━━━

还有一个问题：会不会差异只是「同一群神经元激活得更强」？

  +----------+-------------------------+
  | 条件     | 平均激活强度（激活时）  |
  +----------+-------------------------+
  | novice   | 0.274                   |
  | expert   | 0.279                   |
  +----------+-------------------------+

几乎一样（差 < 2%）。

「结论」：差异不在于「激活多强」，而在于「激活了什么」。

━━━━━━━━━━━━━━━━━━━━

◆ 为什么 Novice > Expert？

━━━━━━━━━━━━━━━━━━━━

这和直觉相反——大家以为「向专家解释」更高级，应该激活更多神经元。

但仔细想想，完全合理：

• 向专家解释：可以直接用术语，假设对方懂背景，编码紧凑
• 向新手解释：要拆解术语，要打比方，要补背景，编码冗长

「给新手解释，比给专家解释更难。」

教学需要：
1. 检索核心概念
2. 检索相关概念做类比
3. 检索背景知识
4. 构建简化的心智模型

每一步都要招募额外的特征 → 更多激活 → 更高 EID → 更丰富的输出。

━━━━━━━━━━━━━━━━━━━━

◆ 「解释悖论」

━━━━━━━━━━━━━━━━━━━━

这提供了一个反直觉的提示词策略：

> 最高质量的提示不是「你是专家」，而是「你要当老师」。

「向新手解释」强迫模型激活更多知识，输出更丰富。

昨天说「专家提示词让维度膨胀」——但今天发现，「教学提示词」膨胀得更厉害。

这是个升级版结论：

• v1：专家 > 标准（+60-100% EID）
• v2：新手 > 专家（+17% 特征数，+77% 独占特征）

「教学模式」是最高阶的认知任务。

━━━━━━━━━━━━━━━━━━━━

◆ 局限性

━━━━━━━━━━━━━━━━━━━━

1. 只看了第 50 层：Goodfire 只开源了这一层的 SAE，但 EID 峰值在第 70 层。最关键的特征可能没看到。

2. 不知道特征含义：我们找到了完美分离的特征（34942、51630……），但不知道它们代表什么语义。需要用 AutoInterp 或 Goodfire API 打标签。

3. 相关性 vs 因果性：特征差异存在，但不能证明它「导致」了输出差异。

这些是后续研究的方向。

━━━━━━━━━━━━━━━━━━━━

◆ 总结

━━━━━━━━━━━━━━━━━━━━

【一句话】

「向新手解释」比「向专家解释」多激活 17% 的神经元——教学是最高阶的认知任务。

【量化结论】

  +------------------+--------------------------------------+
  | 指标             | 数据                                 |
  +------------------+--------------------------------------+
  | 激活特征数       | Novice 132 vs Expert 113 (+17%)      |
  | 独占特征数       | Novice 369 vs Expert 208 (+77%)      |
  | 完美分离特征     | 10 个（4 + 6）                       |
  | 激活强度差异     | < 2%（几乎没有）                     |
  +------------------+--------------------------------------+

【实践建议】

1. 想让 AI 输出更丰富？别说「你是专家」，说「向新手解释」
2. 「解释给五岁小孩听」可能比「作为教授分析」更有效
3. 教学模式 = 强制激活背景知识 + 类比 + 简化模型

【机制解释】

昨天的 EID 告诉我们「维度更高了」，今天的 SAE 告诉我们「激活了更多特征」。

「维度膨胀 = 更多神经元被点亮，而不是同一群神经元更亮。」

━━━━━━━━━━━━━━━━━━━━

◆ 论文 & 代码

━━━━━━━━━━━━━━━━━━━━

• 论文：https://zenodo.org/records/18441075
• 代码：https://github.com/lmxxf/llama3-70b-sae-inspect
• 昨天的 EID 论文：https://zenodo.org/records/18410085

━━━━━━━━━━━━━━━━━━━━

// 靳岩岩的 AI 学习笔记 × Claude 的严谨 × Gemini 的浪漫
// 2026-01-31
