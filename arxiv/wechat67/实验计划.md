# Grokking 流形发现假说 —— 实验计划

**目标**：验证论文《Grokking 作为流形发现》的核心预测，产出可发表的实验数据。

**预计工时**：2-3 天（含代码调试）

**硬件需求**：单卡 GPU（RTX 3090 或更低都行），模型很小

---

## 实验一：内在维度突变（核心实验）

**假说**：Grokking 发生时，中间层表示的内在维度会从"高维锯齿"骤降到"低维流形"。

**步骤**：

1. **复用现有代码**
   - 基础：Nanda et al. 2023 的 Grokking 代码（ICLR Oral，有开源）
   - 仓库：https://github.com/neelnanda-io/grokking
   - 或者用 Power et al. 2022 的原始实现

2. **训练设置**
   - 任务：模加法 $(a + b) \mod p$，取 $p = 97$（质数）
   - 模型：2-3 层 Transformer，hidden_dim = 128
   - 训练集：随机采样 30% 的 $(a, b)$ 对
   - 优化器：AdamW，weight decay = 1.0（重要！）
   - 训练步数：150,000 步（确保观察到 Grokking）

3. **数据采集**
   - 每 1000 步保存一次中间层激活（所有测试样本）
   - 记录：训练 loss、测试 accuracy、中间层激活矩阵

4. **内在维度估计**
   - 方法 A：PCA，看 explained variance ratio 的拐点
   - 方法 B：TwoNN（Facco et al. 2017），更鲁棒
   - 对每个 checkpoint 的激活矩阵计算内在维度

5. **输出**
   - 图 1：训练步数 vs 测试准确率（经典 Grokking 曲线）
   - 图 2：训练步数 vs 内在维度（叠加在同一张图上）
   - 预期：内在维度在测试准确率跃迁附近骤降

**判别标准**：
- ✅ 支持假说：内在维度在 Grokking 附近出现明显折点/骤降
- ❌ 反对假说：内在维度平滑变化，与 Grokking 时间无关

---

## 实验二：注意力熵动态（简单补充）

**假说**：Grokking 过程中，attention 熵呈现"低→高→中"的探索-收敛模式。

**步骤**：

1. 沿用实验一的训练过程
2. 每 1000 步记录 attention matrix
3. 计算每个 head 的 attention 熵：$H = -\sum_i p_i \log p_i$
4. 画图：训练步数 vs 平均 attention 熵

**输出**：
- 图 3：训练步数 vs attention 熵 vs 测试准确率
- 观察熵的峰/谷是否与 Grokking 时间对齐

---

## 实验三：秩约束影响（进阶实验）

**假说**：强制低秩约束会影响 Grokking 的发生时间。

**步骤**：

1. 在中间层添加线性瓶颈：`hidden_dim → bottleneck_dim → hidden_dim`
2. 取不同的 bottleneck_dim：1, 2, 4, 8, 16, 32, 64, 128
3. 对每个配置训练到 150,000 步
4. 记录 Grokking 发生时间（测试准确率首次 > 90% 的步数）

**输出**：
- 图 4：bottleneck_dim vs Grokking 时间
- 预期：
  - bottleneck_dim = 1（等于任务真实自由度）：Grokking 最快
  - bottleneck_dim < 1：Grokking 不发生
  - bottleneck_dim > 1：Grokking 时间随维度增加而增加

---

## 代码结构建议

```
grokking-experiment/
├── train.py              # 训练脚本，保存 checkpoint
├── collect_activations.py # 从 checkpoint 提取激活
├── estimate_dimension.py  # PCA / TwoNN 维度估计
├── plot_results.py        # 画图
├── configs/
│   ├── base.yaml          # 基础配置
│   └── bottleneck.yaml    # 秩约束实验配置
└── results/
    ├── activations/       # 激活数据
    ├── figures/           # 输出图片
    └── logs/              # 训练日志
```

---

## 参考资源

1. **Nanda et al. 代码**：https://github.com/neelnanda-io/grokking
2. **TwoNN 维度估计**：https://github.com/efacco/intrinsic_dimension（或用 scikit-dimension）
3. **原论文**：Power et al. 2022, arXiv:2201.02177

---

## 预期产出

1. **3-4 张图**：支持或反驳流形发现假说
2. **可复现代码**：放 GitHub，论文附链接
3. **论文更新**：根据实验结果补充第 5 节

---

## 风险与备选

**风险**：内在维度估计可能噪声大
**备选**：
- 多跑几个 random seed 取平均
- 换不同的维度估计方法（PCA vs TwoNN vs MLE）
- 如果都很 noisy，说明"维度突变"可能不是主要信号，这本身也是有价值的负结果

---

*实验设计原则：可证伪、可复现、工作量可控*
